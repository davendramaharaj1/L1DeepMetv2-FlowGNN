{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/dvsm3/.conda/envs/deepmet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as osp\n",
    "sys.path\n",
    "sys.path.append('../../L1DeepMETv2/')\n",
    "from graphmetnetwork import GraphMetNetwork\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_cluster import radius_graph, knn_graph\n",
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import model.net as net\n",
    "import model.data_loader as data_loader\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../weights/'\n",
    "data_dir = '../../L1DeepMETv2/data_ttbar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "0it [00:00, ?it/s]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 199708\n",
      "length of train/val data:  798834 199708\n",
      "Training dataloader: 133139, Test dataloader: 33285\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/dvsm3/.conda/envs/deepmet/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "dataloaders = data_loader.fetch_dataloader(data_dir = data_dir, batch_size=6, validation_split=.2)\n",
    "train_dl = dataloaders['train']\n",
    "test_dl = dataloaders['test']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Training dataloader: {}, Test dataloader: {}'.format(len(train_dl), len(test_dl)))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = None\n",
    "for cnt, test_data in enumerate(test_dl):\n",
    "    if cnt == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tensor Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/dvsm3/.conda/envs/deepmet/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cont_test: torch.Size([267, 6])\n",
      "x_cat_test: torch.Size([267, 2])\n",
      "etaphi: torch.Size([267, 2])\n",
      "batch: torch.Size([267])\n",
      "edge_index: torch.Size([2, 1494])\n"
     ]
    }
   ],
   "source": [
    "n_features_cont = 6\n",
    "x_cont_test = test_data.x[:,:n_features_cont] .to(device)  # include puppi\n",
    "x_cat_test = test_data.x[:,n_features_cont:].long().to(device)\n",
    "etaphi_test = torch.cat([test_data.x[:, 3][:, None], test_data.x[:, 4][:, None]], dim=1).to(device=device)\n",
    "batch_test = test_data.batch.to(device)\n",
    "edge_index_test = radius_graph(etaphi_test, r=0.4, batch=batch_test, loop=False, max_num_neighbors=255).to(device=device)\n",
    "print(f'x_cont_test: {x_cont_test.shape}')\n",
    "print(f'x_cat_test: {x_cat_test.shape}')\n",
    "print(f'etaphi: {etaphi_test.shape}')\n",
    "print(f'batch: {batch_test.shape}')\n",
    "print(f'edge_index: {edge_index_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Tensor parameters to Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 267\n"
     ]
    }
   ],
   "source": [
    "x_cont = np.ascontiguousarray(x_cont_test.squeeze(0).cpu().numpy())\n",
    "x_cat = np.ascontiguousarray(x_cat_test.squeeze(0).cpu().numpy())\n",
    "batch = np.ascontiguousarray(batch_test.squeeze(0).cpu().numpy())\n",
    "etaphi = etaphi_test.squeeze(0).cpu().numpy()\n",
    "edge_index = edge_index_test.squeeze(0).cpu().numpy().transpose()\n",
    "num_nodes = x_cont.shape[0]\n",
    "batch_size = batch.shape[0]\n",
    "print(f'Number of nodes: {num_nodes}')\n",
    "assert(num_nodes == batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (graphnet): GraphMETNetwork(\n",
      "    (embed_charge): Embedding(3, 8)\n",
      "    (embed_pdgid): Embedding(7, 8)\n",
      "    (embed_continuous): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (embed_categorical): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (encode_all): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (bn_all): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_continuous): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): EdgeConv(nn=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        ))\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): EdgeConv(nn=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        ))\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (output): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/dvsm3/.conda/envs/deepmet/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:988: UserWarning: 'EdgeConv.jittable' is deprecated and a no-op. Please remove its usage.\n",
      "  warnings.warn(f\"'{self.__class__.__name__}.jittable' is deprecated \"\n"
     ]
    }
   ],
   "source": [
    "prefix = '../../L1DeepMETv2/ckpts_April30_scale_sigmoid'\n",
    "# Restore ckpts\n",
    "restore_ckpt = osp.join(prefix, 'last.pth.tar')\n",
    "norm = torch.tensor([1., 1., 1., 1., 1., 1.]).to(device=device)\n",
    "torch_model = net.Net(continuous_dim=6, categorical_dim=2 , norm=norm).to(device)\n",
    "print(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 62,\n",
       " 'state_dict': OrderedDict([('graphnet.embed_charge.weight',\n",
       "               tensor([[ 0.9152, -1.0589, -0.9910,  0.0120, -1.2543,  0.2998, -0.3684, -0.0260],\n",
       "                       [ 1.1699, -1.1929, -0.4268, -0.7047, -0.3582,  0.5368,  1.0060, -0.7781],\n",
       "                       [-1.1897, -0.7680,  0.9429,  0.2915, -0.2274, -1.3632,  0.6982,  0.4960]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.embed_pdgid.weight',\n",
       "               tensor([[-2.0383, -0.3847, -0.2413,  0.9122, -0.4805,  0.2302, -0.4746,  0.9317],\n",
       "                       [-0.4117,  1.3556,  0.8550,  0.9977, -0.1622,  1.0582, -0.3220, -0.1858],\n",
       "                       [ 0.3344, -1.7237,  0.2500,  0.0249, -1.0838, -0.7614, -0.2512, -1.4239],\n",
       "                       [-0.0926,  0.4536, -0.2328,  1.5914, -0.3767, -1.6118,  0.4281,  0.3517],\n",
       "                       [-0.8126, -1.1399, -0.2381, -0.4232,  0.0113, -1.9791, -0.4646, -1.3267],\n",
       "                       [ 0.1623,  0.1171, -0.4400,  0.8133, -1.5196,  2.1547,  1.1111, -1.5128],\n",
       "                       [-2.0250,  0.8894,  1.1295, -1.7737, -1.0402, -1.3035, -0.5598, -0.0130]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.embed_continuous.0.weight',\n",
       "               tensor([[-0.5198,  0.2914, -0.0195,  0.3422, -0.2245,  0.1846],\n",
       "                       [-0.4170, -0.1938, -0.2800, -0.0356, -0.1603,  0.1396],\n",
       "                       [-0.1805, -0.1111, -0.2351, -0.1149, -0.1347, -0.4671],\n",
       "                       [-0.0910,  0.0320, -0.1111,  0.0798,  0.1879,  0.3672],\n",
       "                       [-0.6301, -0.1794, -0.1667, -0.1458,  0.2014, -0.3199],\n",
       "                       [ 0.3729, -0.0307,  0.0235, -0.0009,  0.2356, -0.4001],\n",
       "                       [ 0.4726, -0.0510, -0.1412,  0.1718, -0.1133,  0.1767],\n",
       "                       [ 0.0455, -0.0182,  0.0487,  0.1988,  0.2355,  0.2938],\n",
       "                       [-0.4597, -0.1802, -0.3717, -0.1472, -0.2679,  0.3283],\n",
       "                       [ 0.1232, -0.3369, -0.2100, -0.1797, -0.0018, -0.0094],\n",
       "                       [ 0.1715, -0.1470,  0.1426,  0.0312,  0.2539,  0.0015],\n",
       "                       [-0.3559,  0.0914,  0.3528,  0.0387, -0.0992, -0.1014],\n",
       "                       [ 0.0626, -0.3333, -0.3364,  0.2583, -0.2236,  0.3076],\n",
       "                       [-0.3306,  0.0552, -0.1572, -0.3771,  0.0157, -0.1987],\n",
       "                       [-0.5702,  0.0018, -0.0113,  0.0562,  0.0509,  0.2252],\n",
       "                       [-0.1714, -0.1777, -0.0817,  0.4233,  0.2242,  0.0200]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.embed_continuous.0.bias',\n",
       "               tensor([-0.0312, -0.0513,  0.0871, -0.4233,  0.3713,  0.3164, -0.2843, -0.0918,\n",
       "                       -0.2188,  0.1339, -0.3240, -0.1274,  0.3631, -0.1676,  0.0605, -0.1710],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.embed_categorical.0.weight',\n",
       "               tensor([[-0.0787, -0.0563, -0.1187, -0.0364,  0.0204, -0.0530, -0.0219, -0.0296,\n",
       "                        -0.2251, -0.2356,  0.0370, -0.0782, -0.1382,  0.1767, -0.0165,  0.2262],\n",
       "                       [-0.0575, -0.1516, -0.0365,  0.0038,  0.0891, -0.0344, -0.1733, -0.1619,\n",
       "                         0.1107, -0.0988, -0.1742, -0.2053,  0.0889, -0.0024,  0.2635,  0.0226],\n",
       "                       [ 0.2004, -0.1992, -0.1722,  0.1961, -0.0091,  0.1812, -0.1146,  0.1062,\n",
       "                        -0.0154, -0.0732, -0.0107, -0.1211, -0.2591, -0.1848, -0.0331, -0.1862],\n",
       "                       [-0.1694,  0.1556,  0.0168, -0.2313,  0.1960,  0.2253,  0.0212, -0.1933,\n",
       "                         0.2024,  0.0875,  0.2323, -0.2126,  0.0847,  0.2396, -0.1411,  0.1251],\n",
       "                       [ 0.0096, -0.0461, -0.1193, -0.1401,  0.2030,  0.0507, -0.0611,  0.1324,\n",
       "                         0.0453, -0.1501, -0.0281, -0.1880, -0.0830,  0.1241,  0.0882, -0.1818],\n",
       "                       [ 0.2564,  0.0326,  0.0949,  0.1497, -0.1188, -0.0616,  0.2600, -0.0207,\n",
       "                         0.1580,  0.1504,  0.0013, -0.2296,  0.1014,  0.1114, -0.2033,  0.0620],\n",
       "                       [ 0.0681, -0.0902,  0.0503,  0.1344, -0.0446, -0.2366, -0.0779, -0.1133,\n",
       "                         0.1727, -0.0132,  0.2520, -0.2005, -0.1813, -0.0109,  0.1670,  0.1771],\n",
       "                       [ 0.1508,  0.1879,  0.0886,  0.0426,  0.1693, -0.1343,  0.0458, -0.1371,\n",
       "                        -0.2286,  0.0853, -0.1171,  0.2315, -0.1872, -0.1182,  0.2166,  0.0972],\n",
       "                       [ 0.1155,  0.1152, -0.2222, -0.0766,  0.0640, -0.2301, -0.0113,  0.1842,\n",
       "                        -0.2519,  0.2597, -0.0399, -0.1806, -0.2088,  0.0780,  0.1366,  0.1855],\n",
       "                       [ 0.0719,  0.0393,  0.0571, -0.0977, -0.0489,  0.2211, -0.0098,  0.0823,\n",
       "                         0.1218, -0.0125,  0.0650, -0.2163,  0.2223,  0.0123, -0.1171, -0.1069],\n",
       "                       [-0.0420,  0.0205, -0.0244,  0.1441, -0.0200, -0.0795,  0.0024,  0.2159,\n",
       "                         0.1760,  0.1429,  0.0565, -0.1157, -0.0979,  0.1854,  0.0518, -0.2142],\n",
       "                       [-0.0606,  0.0532, -0.1870,  0.1019,  0.1149,  0.1593,  0.0366, -0.2269,\n",
       "                         0.0499, -0.1661, -0.1157, -0.1843,  0.1564, -0.0483,  0.1760,  0.1629],\n",
       "                       [-0.1917, -0.2454, -0.1746,  0.0616, -0.1043, -0.1977, -0.0618,  0.1129,\n",
       "                        -0.0261,  0.2283,  0.2088,  0.0397, -0.1768,  0.0630, -0.1193,  0.1926],\n",
       "                       [ 0.0132,  0.1654,  0.1472,  0.0180, -0.2582,  0.2016, -0.0596, -0.1718,\n",
       "                        -0.1537,  0.2106,  0.1356, -0.0096,  0.0643,  0.0652, -0.1648,  0.2329],\n",
       "                       [-0.1621, -0.0787, -0.1285, -0.1518, -0.0752, -0.0572,  0.1987,  0.0454,\n",
       "                         0.1367,  0.1637, -0.1557,  0.0120,  0.0559,  0.1623,  0.0850, -0.0030],\n",
       "                       [ 0.2437, -0.1343,  0.0039, -0.1591,  0.1778,  0.2414, -0.2237, -0.0078,\n",
       "                        -0.1415, -0.0833, -0.1674, -0.0289, -0.1771,  0.1508, -0.1112, -0.1199]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.embed_categorical.0.bias',\n",
       "               tensor([ 0.0177,  0.0115, -0.2634,  0.1663, -0.0457, -0.1453, -0.1966,  0.2019,\n",
       "                        0.1508,  0.1544, -0.2295,  0.0437, -0.0749, -0.0473,  0.1372,  0.2396],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.encode_all.0.weight',\n",
       "               tensor([[-0.0824,  0.1002,  0.1671,  ..., -0.0405, -0.0306, -0.0481],\n",
       "                       [ 0.0017,  0.1078, -0.1271,  ..., -0.1374,  0.1322,  0.0902],\n",
       "                       [ 0.1826, -0.1251, -0.0991,  ...,  0.0467, -0.1638, -0.0425],\n",
       "                       ...,\n",
       "                       [ 0.0923, -0.0543, -0.0378,  ...,  0.1686,  0.1135, -0.0553],\n",
       "                       [-0.1540, -0.0217,  0.0828,  ...,  0.0877,  0.0866,  0.0072],\n",
       "                       [-0.1034, -0.0528, -0.0888,  ..., -0.0109, -0.0097, -0.1030]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.encode_all.0.bias',\n",
       "               tensor([ 0.0819,  0.0416,  0.3016,  0.1200, -0.0896, -0.0943, -0.1135,  0.0494,\n",
       "                        0.1300,  0.1831, -0.1369, -0.1985, -0.0027, -0.1722, -0.1303, -0.0850,\n",
       "                        0.0559,  0.0876, -0.1927,  0.1093,  0.1183,  0.0760,  0.0119,  0.0898,\n",
       "                        0.0099,  0.2143, -0.0117,  0.0417, -0.1255,  0.1992,  0.0699,  0.1225],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.bn_all.weight',\n",
       "               tensor([0.9923, 0.9594, 0.9537, 1.0028, 1.1002, 1.0385, 1.0134, 0.9704, 1.0419,\n",
       "                       0.9487, 0.9355, 0.9831, 1.0129, 0.9872, 1.0009, 0.9825, 1.0314, 0.9836,\n",
       "                       1.0089, 0.9738, 0.9830, 0.9930, 1.0456, 0.9889, 1.0427, 1.0131, 1.0451,\n",
       "                       1.0025, 0.9616, 0.9886, 0.9647, 0.9468], device='cuda:0')),\n",
       "              ('graphnet.bn_all.bias',\n",
       "               tensor([ 0.0294, -0.1186,  0.1331,  0.1048,  0.0914,  0.0490, -0.1401,  0.1369,\n",
       "                       -0.1369, -0.0663,  0.1817,  0.0695, -0.1274,  0.1742, -0.1426, -0.1760,\n",
       "                       -0.1800, -0.0671,  0.1306, -0.1225,  0.1487,  0.2012,  0.0886, -0.1728,\n",
       "                        0.0197,  0.2282,  0.0185, -0.1782,  0.1252, -0.1191, -0.0005,  0.2215],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.bn_all.running_mean',\n",
       "               tensor([ 0.1706, -0.0297,  0.3226,  0.2559, -0.0447,  0.0964, -0.2841,  0.1077,\n",
       "                        0.0779,  0.1106, -0.3209, -0.2656,  0.2375, -0.1043, -0.0970,  0.0286,\n",
       "                       -0.0470,  0.0776, -0.2384,  0.0796,  0.0924,  0.5141,  0.0160,  0.1758,\n",
       "                        0.0478,  0.0885,  0.1992,  0.0821, -0.0447,  0.4201,  0.1252,  0.1072],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.bn_all.running_var',\n",
       "               tensor([0.0807, 0.0060, 0.0292, 0.0206, 0.0027, 0.0244, 0.0203, 0.0400, 0.0219,\n",
       "                       0.0466, 0.0058, 0.0196, 0.0438, 0.0097, 0.0335, 0.0225, 0.0029, 0.0157,\n",
       "                       0.0498, 0.0556, 0.0656, 0.0396, 0.0122, 0.0478, 0.0439, 0.0479, 0.0034,\n",
       "                       0.0210, 0.0143, 0.0307, 0.0315, 0.0655], device='cuda:0')),\n",
       "              ('graphnet.bn_all.num_batches_tracked',\n",
       "               tensor(1547768, device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.0.nn.0.weight',\n",
       "               tensor([[-0.0572, -0.0712, -0.0804,  ..., -0.0655, -0.1202, -0.1024],\n",
       "                       [ 0.0914,  0.0417,  0.0410,  ...,  0.0621,  0.0243, -0.0179],\n",
       "                       [-0.0631,  0.0470, -0.0616,  ...,  0.0208,  0.0840, -0.0131],\n",
       "                       ...,\n",
       "                       [-0.0438,  0.0505, -0.1280,  ..., -0.1271, -0.0480, -0.0774],\n",
       "                       [ 0.1099,  0.0429, -0.0642,  ...,  0.0995,  0.0639, -0.0300],\n",
       "                       [ 0.0573, -0.1065,  0.0176,  ...,  0.1028, -0.0480, -0.1150]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.0.nn.0.bias',\n",
       "               tensor([-0.1704, -0.0006,  0.0746,  0.1750,  0.0991,  0.0825, -0.0736,  0.1520,\n",
       "                       -0.2383, -0.1679,  0.1877,  0.1133,  0.0496,  0.1732, -0.0173, -0.1551,\n",
       "                        0.0876, -0.0205,  0.1291,  0.0257,  0.1774,  0.0649,  0.0647,  0.0317,\n",
       "                       -0.1880,  0.0367, -0.1064, -0.1111,  0.0097, -0.0227, -0.0777,  0.0660],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.1.weight',\n",
       "               tensor([1.0613, 1.0116, 1.0487, 0.9933, 1.0154, 1.0810, 1.0253, 1.0291, 1.0281,\n",
       "                       1.0465, 0.9412, 1.0548, 1.1082, 1.0312, 1.0170, 1.0255, 1.0124, 0.9828,\n",
       "                       1.0011, 1.0229, 1.0092, 1.0742, 1.0064, 1.0090, 1.0262, 1.0497, 1.0360,\n",
       "                       1.0108, 1.0108, 1.0057, 1.0439, 0.9686], device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.1.bias',\n",
       "               tensor([-0.0287, -0.1603,  0.1823,  0.1347,  0.1295,  0.0509, -0.1544,  0.1974,\n",
       "                       -0.1716, -0.0694,  0.2191,  0.1133, -0.1371,  0.1720, -0.1636, -0.1867,\n",
       "                       -0.1447, -0.0891,  0.1313, -0.1214,  0.1767,  0.2064,  0.1199, -0.1927,\n",
       "                       -0.0022,  0.2186, -0.0260, -0.1692,  0.1487, -0.0623,  0.0181,  0.2237],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.1.running_mean',\n",
       "               tensor([ 0.0630,  0.2241,  0.3400,  0.2675,  0.1893,  0.2180,  0.3376,  0.2844,\n",
       "                        0.0558,  0.1802,  0.3598,  0.3026,  0.3303,  0.2022,  0.0700,  0.0928,\n",
       "                        0.4512,  0.2077,  0.3137,  0.3514,  0.2163,  0.4595,  0.3335,  0.1816,\n",
       "                       -0.0031,  0.4913,  0.1094,  0.1157,  0.3252,  0.1866,  0.0019,  0.3272],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.1.running_var',\n",
       "               tensor([0.1196, 0.1893, 0.4683, 0.2620, 0.1410, 0.3270, 0.5172, 0.1104, 0.1125,\n",
       "                       0.3054, 0.4895, 0.1548, 0.2282, 0.0951, 0.1421, 0.2600, 0.7066, 0.1930,\n",
       "                       0.1766, 0.4946, 0.0816, 0.2979, 0.6663, 0.2055, 0.3287, 0.5137, 0.2063,\n",
       "                       0.4251, 0.2645, 0.4067, 0.1502, 0.7304], device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.0.1.num_batches_tracked',\n",
       "               tensor(1547768, device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.0.nn.0.weight',\n",
       "               tensor([[-0.0720, -0.0866, -0.0367,  ...,  0.0486,  0.0093, -0.0275],\n",
       "                       [-0.0118,  0.0290, -0.0501,  ...,  0.0166,  0.0183, -0.0175],\n",
       "                       [ 0.0306,  0.0261,  0.0002,  ...,  0.1206, -0.0796, -0.0476],\n",
       "                       ...,\n",
       "                       [ 0.0428,  0.0372,  0.1029,  ...,  0.0164,  0.0603,  0.0139],\n",
       "                       [ 0.0413, -0.0467, -0.1251,  ...,  0.0867, -0.0717,  0.0681],\n",
       "                       [-0.1286,  0.0994,  0.0421,  ..., -0.0265,  0.0694,  0.0408]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.0.nn.0.bias',\n",
       "               tensor([-0.1454, -0.1933,  0.1318, -0.0242, -0.0554,  0.0439, -0.0753,  0.1040,\n",
       "                       -0.2388,  0.0252, -0.1298,  0.0089,  0.1070, -0.0292, -0.1327, -0.0788,\n",
       "                       -0.1675, -0.0735,  0.0325, -0.1196,  0.0891,  0.1010,  0.0253, -0.0781,\n",
       "                       -0.1670, -0.0202, -0.0866, -0.0707, -0.0169, -0.1365,  0.1752,  0.0314],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.1.weight',\n",
       "               tensor([1.1965, 1.2566, 1.1053, 1.0830, 1.1242, 1.1225, 1.1081, 1.1249, 1.0718,\n",
       "                       1.0580, 1.1950, 1.1960, 1.0842, 1.0971, 1.0160, 1.0541, 1.1143, 1.0818,\n",
       "                       1.1322, 1.0781, 1.0711, 1.1228, 1.0668, 1.0804, 1.1834, 1.1058, 1.2825,\n",
       "                       1.0869, 1.1320, 1.0260, 0.9967, 1.0857], device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.1.bias',\n",
       "               tensor([ 0.0052, -0.1752,  0.1841,  0.1443,  0.0983,  0.0150, -0.1401,  0.2052,\n",
       "                       -0.1861, -0.1008,  0.3177,  0.1276, -0.1402,  0.1816, -0.1572, -0.2073,\n",
       "                       -0.1772, -0.1478,  0.1647, -0.1150,  0.1594,  0.2058,  0.1336, -0.2053,\n",
       "                       -0.0042,  0.1980, -0.0637, -0.1675,  0.1511, -0.1432,  0.0684,  0.2177],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.1.running_mean',\n",
       "               tensor([-0.1168, -0.1603,  0.1748,  0.1794,  0.0709,  0.1779,  0.0395,  0.3390,\n",
       "                        0.0147,  0.1149,  0.0883,  0.3052,  0.1736,  0.1574,  0.0164,  0.1730,\n",
       "                        0.1222,  0.1048,  0.3430,  0.1092,  0.3576,  0.3486,  0.5608,  0.3145,\n",
       "                       -0.2268,  0.2096,  0.1658,  0.1573,  0.2887,  0.1715,  0.7447,  0.2168],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.1.running_var',\n",
       "               tensor([0.1029, 0.1057, 0.3594, 0.5108, 0.1587, 0.3606, 0.1509, 0.3542, 0.4352,\n",
       "                       0.4158, 0.0926, 0.2904, 0.5329, 0.2763, 0.6401, 0.7127, 0.2649, 0.1717,\n",
       "                       0.3497, 0.1531, 1.4177, 0.1628, 1.1111, 0.4315, 0.1891, 0.0838, 0.0897,\n",
       "                       0.3203, 0.3620, 0.5244, 2.2843, 0.3078], device='cuda:0')),\n",
       "              ('graphnet.conv_continuous.1.1.num_batches_tracked',\n",
       "               tensor(1547768, device='cuda:0')),\n",
       "              ('graphnet.output.0.weight',\n",
       "               tensor([[-1.5599e-01, -1.3244e-02, -1.3670e-01, -5.6949e-02, -2.7375e-01,\n",
       "                        -2.5336e-02, -1.0546e-01, -4.0593e-02,  1.2195e-01,  2.0914e-02,\n",
       "                         8.1868e-02,  5.8809e-03, -3.5005e-02, -8.3066e-02,  1.0313e-01,\n",
       "                         9.1293e-02,  4.8431e-02,  5.7066e-02,  7.5503e-02,  6.0517e-02,\n",
       "                        -5.7531e-02,  7.3876e-03,  1.2300e-01, -3.0529e-02,  2.4837e-01,\n",
       "                         1.1439e-01,  2.2638e-01,  1.8057e-01, -5.2733e-02,  1.6312e-01,\n",
       "                        -2.9093e-02, -1.3805e-01],\n",
       "                       [ 2.0522e-03, -1.2980e-01,  1.9843e-01,  1.5979e-01,  1.5782e-03,\n",
       "                         2.2701e-01, -2.0787e-01,  2.8247e-01, -2.3325e-01, -2.9995e-01,\n",
       "                         5.3057e-02,  2.2886e-01,  1.6938e-02,  1.7797e-01,  1.7411e-02,\n",
       "                        -2.7790e-01, -8.9879e-02, -1.7873e-02,  3.2177e-01, -3.9112e-01,\n",
       "                         2.2704e-01,  2.4911e-01, -6.3030e-02, -1.4372e-01,  1.5839e-01,\n",
       "                         1.0155e-01,  3.9964e-01, -1.9504e-01,  1.9941e-01, -1.1548e-01,\n",
       "                         5.4367e-02,  2.5947e-01],\n",
       "                       [ 4.1090e-02,  3.9341e-02,  1.6147e-01,  1.9897e-01,  1.0743e-01,\n",
       "                        -1.0116e-01,  9.1679e-02,  1.9156e-01,  2.2167e-02,  5.0456e-02,\n",
       "                         7.8899e-02, -1.7079e-01, -1.1966e-01,  1.3530e-01, -1.6584e-01,\n",
       "                        -1.2997e-01,  1.1125e-01, -6.5675e-02,  1.5639e-01,  1.2968e-01,\n",
       "                         1.0776e-01,  1.0962e-01,  2.2358e-01, -1.2409e-01, -1.7797e-01,\n",
       "                         1.6263e-01, -8.5739e-02,  4.8682e-02, -7.0963e-02,  1.0458e-02,\n",
       "                         1.1131e-02,  8.7225e-02],\n",
       "                       [-2.2126e-01, -3.3541e-01,  2.1148e-01,  4.2375e-02, -7.3712e-02,\n",
       "                         1.3610e-01, -2.1809e-01,  1.4117e-01, -2.2810e-01, -1.8819e-01,\n",
       "                         2.4607e-01,  3.7348e-01,  2.4842e-01,  4.3417e-01, -2.6597e-01,\n",
       "                        -1.7069e-01, -1.6839e-01, -5.2772e-02,  3.4228e-01, -1.4041e-01,\n",
       "                         9.0893e-02,  3.4902e-01, -8.7104e-02, -1.8302e-01, -5.1990e-02,\n",
       "                         5.0805e-01,  2.0690e-01, -2.4281e-01,  2.6942e-01,  8.8062e-02,\n",
       "                        -1.1052e-01,  1.2248e-01],\n",
       "                       [ 5.8912e-02, -1.2960e-01, -8.0924e-03,  1.0797e-01,  5.7441e-02,\n",
       "                         1.0048e-01, -2.6011e-02,  2.6538e-02,  1.7115e-01, -9.6650e-02,\n",
       "                        -1.3975e-01, -1.8085e-01,  1.4362e-01, -6.2682e-02, -4.0193e-02,\n",
       "                        -3.7618e-02, -1.5393e-02,  1.4534e-01,  1.1454e-01,  1.5886e-01,\n",
       "                         1.6055e-01, -1.4832e-01, -4.9727e-02,  1.7731e-01, -1.6553e-01,\n",
       "                        -5.3954e-02, -3.4738e-02, -3.8586e-03,  3.7578e-02, -5.9365e-02,\n",
       "                        -4.8307e-03,  3.3420e-02],\n",
       "                       [-2.9330e-01, -1.8035e-01,  1.7254e-01,  2.9704e-02,  2.4647e-02,\n",
       "                         3.6587e-02, -1.6253e-01, -7.1142e-02,  1.2808e-01,  1.0927e-01,\n",
       "                        -1.0437e-01, -4.8727e-02, -3.7278e-02,  2.2808e-01, -8.4573e-02,\n",
       "                        -2.4996e-01, -2.6138e-01, -9.1159e-02, -3.4183e-02,  3.7001e-02,\n",
       "                         1.3842e-01,  1.6883e-01, -5.2981e-02, -2.7565e-01, -5.9460e-02,\n",
       "                         6.3458e-02,  7.5641e-02, -2.4266e-01,  1.7923e-01,  3.3595e-03,\n",
       "                        -7.5836e-02, -2.6361e-02],\n",
       "                       [-7.3452e-02, -3.5442e-01,  7.0410e-02,  4.9539e-02, -1.1002e-01,\n",
       "                         9.2038e-02, -2.4782e-01,  4.9853e-02, -3.4224e-01,  9.3552e-03,\n",
       "                         2.3987e-01,  1.0389e-01,  1.7373e-01,  3.7404e-01, -1.4854e-02,\n",
       "                        -2.9908e-01, -2.9079e-01,  5.7824e-02,  1.3927e-03, -1.2550e-02,\n",
       "                         2.2362e-01,  3.3901e-01,  7.7569e-02, -2.1281e-01, -2.4505e-01,\n",
       "                         3.1785e-01,  1.8955e-01, -2.1132e-01,  2.7436e-01, -1.4065e-01,\n",
       "                         7.0900e-02,  1.4314e-01],\n",
       "                       [ 1.2304e-01,  4.2670e-02, -1.6342e-01, -3.3257e-01, -2.6892e-01,\n",
       "                         2.0655e-01, -7.6296e-02, -1.9780e-01, -4.2058e-02,  9.8720e-02,\n",
       "                         2.4260e-01, -6.8653e-02, -7.0552e-02, -1.8423e-01,  2.2140e-01,\n",
       "                        -1.8069e-01, -3.9193e-01,  7.4422e-02, -1.2450e-01,  2.3678e-02,\n",
       "                        -1.5111e-01,  4.3713e-02, -2.1691e-01, -7.1410e-02,  3.3251e-01,\n",
       "                         7.2568e-02,  1.8064e-01,  6.0826e-02, -1.1438e-01, -5.3062e-02,\n",
       "                        -2.7477e-02, -2.3022e-02],\n",
       "                       [-1.1707e-01, -1.1344e-01, -1.8515e-01, -3.7956e-02,  2.0119e-01,\n",
       "                         9.2630e-02,  7.3965e-03, -5.3228e-02,  8.9899e-02,  9.6625e-02,\n",
       "                         9.7066e-02,  3.4623e-02, -8.4304e-03,  5.4420e-02,  4.1807e-02,\n",
       "                         2.7775e-02,  1.5157e-01,  1.5959e-01, -1.1119e-02,  1.2004e-01,\n",
       "                        -2.8626e-02,  4.9813e-02,  1.6595e-02,  1.6126e-01,  4.2604e-02,\n",
       "                        -1.1485e-01, -9.5046e-04,  4.8445e-02,  2.1702e-05,  1.4019e-01,\n",
       "                        -1.7640e-01,  1.7536e-01],\n",
       "                       [-5.9261e-02, -2.0277e-02, -1.3439e-03,  5.7264e-03,  8.2752e-02,\n",
       "                         5.3782e-02, -4.8103e-02, -2.5927e-02, -8.0256e-02,  1.5114e-01,\n",
       "                        -1.1352e-01,  4.7293e-02,  1.4260e-01, -2.5008e-02,  1.4050e-01,\n",
       "                         1.1484e-01,  3.5595e-02,  1.1344e-02, -4.3041e-02,  1.5411e-02,\n",
       "                         8.4802e-02, -1.8654e-01, -2.2846e-01,  2.4324e-02, -9.2469e-02,\n",
       "                         9.3957e-02,  1.5892e-01,  1.1066e-01, -1.4828e-01,  1.0546e-01,\n",
       "                         1.4722e-01, -9.6509e-03],\n",
       "                       [ 6.4302e-02, -1.7071e-01, -4.8383e-02, -2.0273e-01, -1.1446e-01,\n",
       "                         1.5013e-01,  1.0172e-01, -1.1191e-02,  5.4274e-02, -3.0241e-02,\n",
       "                        -5.0084e-02, -1.9140e-01,  9.5367e-03,  1.3870e-01,  9.3885e-02,\n",
       "                        -2.2540e-02, -4.2487e-02, -6.3854e-02, -9.6144e-02,  1.1929e-02,\n",
       "                        -7.0999e-02,  3.3783e-02, -2.0782e-02,  1.4875e-01,  1.4299e-01,\n",
       "                        -2.1094e-02,  2.3498e-01,  7.6647e-03, -5.6564e-02,  6.4554e-02,\n",
       "                         5.1093e-02, -4.6189e-02],\n",
       "                       [ 6.1956e-02, -1.4332e-01,  6.0020e-02, -1.8207e-01, -8.4925e-02,\n",
       "                         1.1589e-01,  1.6829e-01, -2.3386e-02, -5.4224e-03,  1.7902e-01,\n",
       "                         9.3749e-02, -1.1386e-02,  1.4897e-02, -3.4069e-02, -2.3819e-02,\n",
       "                         2.7106e-02,  7.7637e-02,  2.0315e-01, -1.8578e-02,  6.2269e-03,\n",
       "                         1.2294e-01, -1.6897e-01, -3.0648e-02, -1.3427e-01, -8.5865e-02,\n",
       "                        -1.5209e-01,  7.0122e-02,  1.8258e-01,  8.7959e-03,  2.0936e-01,\n",
       "                         1.9659e-01,  1.1210e-01],\n",
       "                       [ 2.3612e-01,  1.0247e-02, -7.1183e-02, -4.3291e-02,  1.0450e-01,\n",
       "                         3.2396e-01, -1.9208e-01, -2.5001e-03, -7.7701e-02,  7.4952e-02,\n",
       "                        -9.5868e-02,  1.7305e-01, -1.2406e-01,  1.8735e-01, -1.9968e-01,\n",
       "                        -8.5916e-02, -6.3430e-03, -7.4598e-02,  2.9363e-01, -2.9919e-02,\n",
       "                         1.8361e-01, -5.3581e-03,  8.8853e-02, -1.3254e-03,  3.0984e-01,\n",
       "                         8.0149e-03,  1.4607e-01,  3.2092e-02,  1.4682e-01, -1.5072e-02,\n",
       "                         1.8731e-01,  1.0454e-01],\n",
       "                       [-9.2172e-02,  3.3645e-02, -2.2766e-01,  5.0822e-02,  9.9523e-02,\n",
       "                         9.2717e-02,  7.8022e-02, -2.1060e-01, -7.2768e-02, -1.2609e-01,\n",
       "                         2.2638e-02, -9.9392e-02,  1.9941e-02,  3.8977e-02,  1.6268e-01,\n",
       "                        -1.0387e-01,  1.4506e-01,  1.8524e-01,  7.0657e-02,  5.3929e-02,\n",
       "                         5.1589e-02,  1.3359e-01,  1.3966e-01, -8.2196e-02, -1.5192e-01,\n",
       "                        -3.8124e-02,  6.1831e-03,  9.9824e-02, -6.6253e-02,  1.7459e-01,\n",
       "                         1.0695e-01,  1.1999e-02],\n",
       "                       [ 1.8863e-01,  1.2491e-01, -3.4440e-03,  8.0302e-02, -7.1904e-02,\n",
       "                         4.3146e-02, -6.7346e-03,  5.5194e-02, -2.2000e-02,  1.5028e-01,\n",
       "                        -3.3788e-02, -1.3236e-02, -5.0530e-02, -3.0306e-04,  1.0657e-01,\n",
       "                         1.4551e-01,  8.5223e-02,  1.5866e-01,  1.0040e-01,  1.8225e-01,\n",
       "                         3.2985e-02,  9.5781e-02,  1.0171e-01, -8.8423e-03, -1.0135e-01,\n",
       "                        -6.2228e-02, -1.5066e-01, -8.2720e-02,  4.1512e-03, -1.1448e-01,\n",
       "                        -1.3355e-01, -1.2150e-01],\n",
       "                       [ 6.7922e-02,  1.2660e-03, -2.0317e-01, -2.9238e-01, -1.5208e-01,\n",
       "                         2.1129e-01,  1.4550e-01,  6.6467e-02, -1.0763e-01,  8.9883e-02,\n",
       "                         9.5132e-02, -1.8320e-01,  5.7835e-02, -2.0030e-03, -4.1549e-03,\n",
       "                        -1.7533e-02,  1.1345e-01, -2.8151e-02, -1.0354e-01,  8.0778e-02,\n",
       "                        -8.4691e-02, -8.9517e-02, -2.2098e-01,  1.2374e-01, -3.7925e-02,\n",
       "                        -1.0231e-01,  2.3641e-01, -4.6626e-02,  1.1894e-01,  1.6920e-02,\n",
       "                         4.3736e-03,  1.3202e-01]], device='cuda:0')),\n",
       "              ('graphnet.output.0.bias',\n",
       "               tensor([-0.1482,  0.2310,  0.1582,  0.2118, -0.1427,  0.2435,  0.0996, -0.2070,\n",
       "                       -0.1553,  0.0136, -0.0458, -0.0912,  0.1787, -0.3149, -0.1577, -0.1590],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.output.2.weight',\n",
       "               tensor([[-0.2729,  0.3485,  0.2876,  0.4687, -0.1262,  0.2399,  0.4152, -0.4882,\n",
       "                        -0.1926, -0.1931, -0.1232, -0.3861,  0.3304, -0.2170, -0.1341, -0.3201]],\n",
       "                      device='cuda:0')),\n",
       "              ('graphnet.output.2.bias', tensor([0.3963], device='cuda:0'))]),\n",
       " 'optim_dict': {'state': {0: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[-0.1302, -0.1088, -0.0791, -0.0104,  0.1173, -0.0704, -0.2011, -0.0783],\n",
       "            [ 0.0139,  0.1275,  0.2724, -0.1274, -0.0845,  0.0944,  0.1008, -0.4343],\n",
       "            [ 0.1165,  0.0191, -0.2897,  0.0154,  0.0770, -0.0191,  0.0995,  0.6255]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[0.2272, 0.2565, 0.5129, 0.1997, 0.2783, 0.2693, 0.2162, 0.7961],\n",
       "            [0.3423, 0.4160, 0.5396, 0.2456, 0.3312, 0.2369, 0.2491, 0.8890],\n",
       "            [0.2469, 0.3628, 0.4733, 0.1843, 0.2168, 0.1856, 0.2120, 0.8091]],\n",
       "           device='cuda:0')},\n",
       "   1: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "            [-2.8127e-02, -1.6967e-02, -1.4283e-02,  1.3674e-04, -1.0053e-01,\n",
       "             -7.5054e-03, -9.1903e-03, -4.4488e-02],\n",
       "            [-2.5298e-02,  2.8491e-02, -6.6175e-02,  1.7301e-02,  7.6659e-03,\n",
       "              2.8833e-03,  3.7180e-02, -5.3821e-02],\n",
       "            [ 9.7040e-02,  9.6005e-02,  1.3142e-01,  1.3591e-01,  9.0159e-02,\n",
       "              6.7604e-03, -2.6992e-01,  3.5978e-02],\n",
       "            [-6.3849e-02, -1.3112e-01,  1.3317e-01, -7.1988e-02,  6.5378e-03,\n",
       "              2.3969e-01, -1.0554e-01,  4.0529e-01],\n",
       "            [-1.2860e-01,  6.0080e-02, -3.0732e-01, -6.7742e-03, -5.5147e-02,\n",
       "             -1.4867e-01,  3.1802e-01, -3.7761e-01]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "            [0.0442, 0.0828, 0.0702, 0.0665, 0.1334, 0.0625, 0.1400, 0.1635],\n",
       "            [0.0309, 0.0637, 0.1415, 0.1214, 0.0527, 0.0385, 0.1445, 0.1675],\n",
       "            [0.1725, 0.1903, 0.1661, 0.3649, 0.2295, 0.2045, 0.4556, 0.3058],\n",
       "            [0.2003, 0.3526, 0.3076, 0.8536, 0.1917, 0.4155, 0.5477, 0.6542],\n",
       "            [0.3309, 0.3257, 0.4015, 0.4608, 0.3111, 0.2875, 0.4885, 0.8835]],\n",
       "           device='cuda:0')},\n",
       "   2: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[-1.6795e-01,  6.8452e-02,  9.5724e-02, -2.3560e+00,  1.0922e+00,\n",
       "              2.2217e-01],\n",
       "            [-1.0399e-01,  2.2029e-01,  1.3039e-01, -3.4299e-01,  7.1382e-02,\n",
       "              1.8743e-01],\n",
       "            [-4.7526e-02, -2.2610e-02,  5.1367e-02, -1.0041e-01,  4.8634e-01,\n",
       "              1.4528e-02],\n",
       "            [ 2.4757e-01, -6.6394e-02,  2.8919e-02,  6.8806e-01, -5.7215e-01,\n",
       "             -4.3729e-02],\n",
       "            [-7.1136e-02,  2.2319e-01,  9.1531e-02, -9.6249e-01,  1.0220e+00,\n",
       "              6.4911e-01],\n",
       "            [-3.4881e-01,  1.0760e-03, -3.0973e-02, -4.8761e-01,  7.0550e-02,\n",
       "              8.2712e-03],\n",
       "            [-1.7971e-01, -8.0786e-02, -1.4387e-01,  1.8144e+00, -1.1538e+00,\n",
       "             -1.8827e-01],\n",
       "            [ 3.3137e-01,  1.0898e-01,  7.7178e-02, -7.0743e-01,  7.6047e-01,\n",
       "              3.3750e-02],\n",
       "            [ 5.6637e-02,  9.0011e-02,  8.9748e-03, -8.7291e-01,  4.4771e-01,\n",
       "              6.9722e-02],\n",
       "            [ 1.8912e-02, -6.4043e-02, -1.4333e-01,  8.4043e-01, -6.3291e-01,\n",
       "             -2.6436e-01],\n",
       "            [ 3.6239e-02, -1.6974e-01, -8.5074e-02,  7.0307e-01, -5.2425e-01,\n",
       "             -3.0041e-03],\n",
       "            [-2.6062e-01,  1.3995e-01,  1.1338e-01, -1.7622e+00,  6.7194e-01,\n",
       "              2.9626e-01],\n",
       "            [ 1.7580e-01, -3.2973e-02,  5.1056e-02,  4.1622e-01, -8.5906e-02,\n",
       "             -1.4798e-01],\n",
       "            [ 2.4145e-02, -6.5866e-02,  2.8967e-02, -1.0861e+00,  1.5891e+00,\n",
       "              4.9656e-01],\n",
       "            [-1.4714e-01,  5.6252e-01,  2.7677e-01, -3.9425e+00,  1.7546e+00,\n",
       "              4.6998e-01],\n",
       "            [-3.0238e-01,  3.9896e-02,  3.6279e-02, -1.2715e+00,  6.1299e-01,\n",
       "             -1.1611e-01]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[3.2634e-01, 3.7226e-01, 3.4764e-01, 2.2731e+01, 2.6421e+01, 1.3351e+00],\n",
       "            [5.3767e-01, 6.7060e-01, 6.2245e-01, 1.4767e+01, 4.8087e+01, 6.7061e-01],\n",
       "            [4.5883e-01, 5.8495e-01, 5.7750e-01, 1.0372e+01, 2.0529e+01, 5.4788e-01],\n",
       "            [9.8786e-01, 1.6455e+00, 1.5224e+00, 1.7269e+01, 2.0868e+01, 6.1861e-01],\n",
       "            [4.2057e-01, 6.7466e-01, 6.2889e-01, 3.8786e+01, 5.0473e+01, 1.7438e+00],\n",
       "            [1.2869e+00, 1.1320e+00, 1.0606e+00, 8.2993e+00, 8.4341e+00, 4.4410e-01],\n",
       "            [1.2593e+00, 1.5361e+00, 1.4436e+00, 5.4554e+01, 1.5032e+02, 1.9970e+00],\n",
       "            [9.9679e-01, 7.7236e-01, 7.6123e-01, 1.4118e+01, 1.5933e+01, 4.1730e-01],\n",
       "            [1.6926e-01, 1.2507e-01, 1.1643e-01, 8.6581e+00, 7.5478e+00, 4.4884e-01],\n",
       "            [6.0528e-01, 1.1016e+00, 1.1291e+00, 2.2071e+01, 6.4796e+01, 6.1338e-01],\n",
       "            [3.1372e-01, 2.8834e-01, 2.8569e-01, 4.7434e+00, 5.4930e+00, 2.9386e-01],\n",
       "            [5.7323e-01, 7.3681e-01, 7.0469e-01, 1.4519e+01, 1.9507e+01, 6.2701e-01],\n",
       "            [3.8637e-01, 3.3617e-01, 3.4464e-01, 8.2588e+00, 1.0463e+01, 1.9279e-01],\n",
       "            [3.9244e-01, 3.8689e-01, 3.0362e-01, 9.9269e+00, 4.0862e+01, 9.7225e-01],\n",
       "            [1.5936e+00, 2.8277e+00, 2.5594e+00, 1.2870e+02, 2.3865e+02, 2.7329e+00],\n",
       "            [6.4695e-01, 6.8098e-01, 6.5039e-01, 9.8902e+00, 2.1250e+01, 6.2515e-01]],\n",
       "           device='cuda:0')},\n",
       "   3: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([ 0.0357,  0.0295, -0.0103, -0.0381,  0.5019,  0.0007, -0.0712, -0.0027,\n",
       "             0.0184, -0.2131, -0.0491,  0.0310, -0.0642,  0.3654,  0.1525, -0.1374],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.8167, 0.4977, 0.5229, 0.3584, 0.9965, 0.1467, 1.3510, 0.2036, 0.2147,\n",
       "            0.1733, 0.1994, 0.3381, 0.0663, 0.6501, 0.2407, 0.5804],\n",
       "           device='cuda:0')},\n",
       "   4: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[ 2.3406e-01, -4.8574e-02, -1.7736e-01, -6.3277e-02, -7.3475e-02,\n",
       "              1.8156e-01, -4.3021e-02, -8.9727e-02,  5.1152e-01,  1.8475e-02,\n",
       "             -1.9207e-01,  5.5152e-01, -3.7010e-01,  1.1020e+00,  4.5212e-01,\n",
       "             -2.3469e-01],\n",
       "            [-7.1083e-01,  3.2314e-01,  1.0850e-01,  5.5933e-01, -2.4716e-01,\n",
       "             -5.1698e-01, -7.2807e-01,  6.3444e-01, -5.1685e-01,  4.5797e-01,\n",
       "              6.4942e-01, -6.7958e-01,  1.4111e-01, -1.0506e+00, -5.1944e-01,\n",
       "              9.1581e-01],\n",
       "            [-1.5484e+00,  4.3550e-01,  9.0757e-01,  6.4526e-01,  1.9941e-01,\n",
       "             -1.1773e+00, -2.4807e-01,  8.1668e-01, -6.3153e-01,  1.3134e-01,\n",
       "              6.9335e-01, -9.7228e-01,  3.0701e-01, -1.5219e+00, -7.7497e-01,\n",
       "              7.8519e-01],\n",
       "            [ 9.7678e-01, -1.8596e-01, -5.6425e-01, -4.1461e-01, -5.7058e-02,\n",
       "              7.8239e-01,  1.3637e-01, -5.2907e-01,  6.7823e-01, -5.1338e-01,\n",
       "             -5.7470e-01,  7.6524e-01,  2.7904e-02,  7.4880e-01,  4.0225e-01,\n",
       "             -6.0709e-01],\n",
       "            [-8.1881e-02,  9.9810e-02, -2.0660e-01,  2.5163e-01, -2.8548e-01,\n",
       "             -5.3806e-02, -5.1060e-01,  2.5949e-01, -2.6057e-01,  5.7973e-01,\n",
       "              3.9777e-01, -3.3040e-01, -2.8158e-01,  2.3461e-01, -1.9654e-02,\n",
       "              4.4718e-01],\n",
       "            [ 2.9804e-01, -3.1836e-04,  2.0344e-02, -2.9157e-01,  2.8055e-01,\n",
       "              2.8247e-01,  3.7224e-01, -3.3357e-01,  7.7016e-01, -7.8436e-01,\n",
       "             -5.7172e-01,  6.8742e-01,  1.9128e-01,  5.0664e-01,  2.5028e-01,\n",
       "             -6.2436e-01],\n",
       "            [ 2.3370e+00, -1.0719e-01, -1.5967e+00, -7.8260e-01, -2.5283e-01,\n",
       "              1.9954e+00, -2.6046e-01, -1.0760e+00,  1.4821e+00, -8.1116e-01,\n",
       "             -1.0339e+00,  1.3463e+00,  5.9392e-02,  2.1421e+00,  8.3906e-01,\n",
       "             -9.9159e-01],\n",
       "            [-1.1844e+00,  2.9194e-01,  6.0704e-01,  5.6841e-01,  7.4502e-03,\n",
       "             -9.2718e-01, -3.3328e-01,  7.0379e-01, -5.4924e-01,  3.6542e-02,\n",
       "              5.7247e-01, -7.0609e-01,  3.5649e-01, -1.7513e+00, -7.2833e-01,\n",
       "              7.4622e-01],\n",
       "            [-1.0178e+00, -9.3413e-02,  7.1033e-01,  3.2876e-01,  3.9726e-02,\n",
       "             -9.2891e-01,  1.9662e-01,  4.6608e-01, -7.8652e-01,  9.6952e-01,\n",
       "              5.9679e-01, -6.3110e-01, -6.5705e-01,  1.8250e-01,  1.1433e-02,\n",
       "              3.7283e-01],\n",
       "            [-2.0345e+00,  4.8133e-01,  1.2280e+00,  8.1792e-01,  2.5137e-01,\n",
       "             -1.5832e+00, -2.2465e-01,  1.0489e+00, -1.0843e+00,  4.7139e-01,\n",
       "              8.9046e-01, -1.2145e+00,  5.0914e-01, -2.3899e+00, -1.0140e+00,\n",
       "              1.2386e+00],\n",
       "            [-1.1182e+00,  1.3941e-01,  6.0054e-01,  5.1391e-01, -4.3948e-02,\n",
       "             -9.3233e-01, -2.1020e-01,  6.5078e-01, -9.7199e-01,  5.5832e-01,\n",
       "              7.3891e-01, -9.9586e-01,  6.0306e-02, -1.4387e+00, -6.2923e-01,\n",
       "              7.8740e-01],\n",
       "            [ 6.0948e-01, -1.6563e-01, -4.0592e-01, -2.1233e-01, -1.4087e-01,\n",
       "              4.6112e-01,  6.0504e-03, -2.7942e-01,  4.4196e-02,  4.5237e-01,\n",
       "             -1.3377e-01,  2.6941e-01, -3.1369e-01,  9.6125e-01,  4.2458e-01,\n",
       "             -9.6096e-02],\n",
       "            [-1.8737e-01,  4.6118e-02, -2.8207e-02,  1.9627e-01, -1.6759e-01,\n",
       "             -1.5900e-01, -2.8058e-01,  2.1970e-01, -2.4126e-01, -6.6853e-02,\n",
       "              2.0293e-01, -2.2913e-01,  2.5160e-01, -1.0512e+00, -3.6176e-01,\n",
       "              3.3574e-01],\n",
       "            [ 1.0295e+00, -1.2614e-02, -7.0802e-01, -3.4099e-01, -9.5259e-02,\n",
       "              8.9375e-01, -1.3700e-01, -4.7257e-01,  5.6065e-01, -2.9140e-01,\n",
       "             -4.4494e-01,  5.3714e-01,  1.4999e-01,  7.3515e-01,  3.0461e-01,\n",
       "             -3.2134e-01],\n",
       "            [-3.6612e-01,  5.5396e-02,  2.6700e-01,  1.0795e-01,  8.7520e-02,\n",
       "             -2.9403e-01,  5.6405e-02,  1.5097e-01, -1.0896e-01,  1.8501e-01,\n",
       "              8.1488e-02, -3.7407e-02, -6.2743e-03, -1.1912e-01, -2.0380e-02,\n",
       "              1.7786e-01],\n",
       "            [ 1.2317e+00, -4.9161e-01, -6.5864e-01, -5.6667e-01, -1.6668e-01,\n",
       "              8.7915e-01,  3.7113e-01, -6.9393e-01,  7.4023e-01, -7.3835e-01,\n",
       "             -6.8410e-01,  9.3232e-01, -2.3938e-01,  9.0293e-01,  5.3780e-01,\n",
       "             -1.0341e+00]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[ 6.8765,  0.2678,  3.4340,  1.5926,  1.3836,  4.4659,  2.7582,  2.3269,\n",
       "              7.5403,  6.9803,  4.0862, 10.3414,  3.4947, 29.6951,  5.4787,  4.4956],\n",
       "            [ 6.4463,  0.5339,  3.0905,  1.2088,  0.8219,  3.7818,  1.7640,  1.8160,\n",
       "              4.2807,  4.2147,  1.6547,  5.9033,  1.9093, 12.6032,  2.1571,  3.2868],\n",
       "            [ 9.0601,  0.4474,  7.1610,  1.2267,  3.0724,  5.4951,  4.7900,  1.8006,\n",
       "              8.9983,  7.7713,  3.4918, 11.3160,  2.9979, 17.0196,  3.2098,  4.4626],\n",
       "            [ 5.8654,  0.6135,  2.6991,  1.1524,  0.7292,  3.5356,  1.6531,  1.7272,\n",
       "              5.7107,  2.4924,  2.8452,  8.0299,  2.1375, 15.4974,  3.5178,  3.4390],\n",
       "            [ 4.9000,  0.5040,  2.4852,  1.0290,  0.8572,  2.7961,  1.9048,  1.4823,\n",
       "              4.1916,  4.5145,  1.9636,  5.1184,  1.5333, 12.7132,  2.4154,  3.5008],\n",
       "            [ 3.4724,  0.1919,  2.1883,  0.5538,  0.7922,  2.2406,  1.3289,  0.8455,\n",
       "              4.0894,  2.5217,  1.7432,  4.9541,  1.4326, 10.6030,  1.8727,  1.6087],\n",
       "            [11.2025,  0.3447,  7.6780,  1.1656,  2.7810,  7.4818,  2.8536,  2.0258,\n",
       "             10.8696,  5.0775,  4.6841, 14.6315,  1.9154, 17.8696,  3.8247,  3.3439],\n",
       "            [ 7.8793,  0.3004,  4.0040,  1.2934,  0.9856,  5.0055,  1.7571,  2.0397,\n",
       "              6.0847,  3.2037,  2.7130,  9.4635,  2.0354, 17.5759,  3.2978,  2.9037],\n",
       "            [11.4922,  0.7369,  5.6432,  2.0804,  1.8067,  7.2413,  2.7382,  3.2165,\n",
       "             10.0110,  3.7694,  4.8238, 16.0178,  4.9827, 41.3469,  7.4392,  6.4419],\n",
       "            [ 8.6069,  0.5288,  4.1652,  1.7422,  1.6760,  5.2992,  2.3476,  2.6243,\n",
       "             12.2901,  5.6756,  5.3875, 15.7448,  2.7613, 33.4208,  6.3980,  4.5495],\n",
       "            [ 8.2593,  0.7434,  3.3359,  1.9206,  0.7921,  5.4340,  2.6418,  2.8489,\n",
       "              8.6460,  3.1154,  4.7395, 13.5018,  2.6215, 25.7909,  6.1139,  5.6185],\n",
       "            [ 8.4980,  1.4174,  4.2499,  2.2037,  2.2444,  4.3063,  4.4305,  3.0031,\n",
       "              8.1288,  9.2617,  4.0113, 11.9057,  3.1540, 25.9104,  4.1470,  6.3775],\n",
       "            [ 8.2575,  0.2864,  5.1317,  0.9811,  1.6418,  5.6622,  1.8297,  1.6848,\n",
       "              8.3456,  4.6738,  3.3203, 11.2600,  1.7703, 15.8385,  3.1400,  3.2464],\n",
       "            [ 2.9684,  0.1482,  1.7188,  0.4555,  0.7447,  2.3105,  0.6840,  0.7675,\n",
       "              5.3333,  1.6359,  2.2811,  5.9963,  0.5219,  7.2516,  1.4985,  0.9557],\n",
       "            [ 7.9821,  0.3810,  4.5268,  1.4482,  1.2708,  5.2931,  3.1117,  2.1825,\n",
       "              4.5975,  6.0349,  3.0737, 10.1423,  2.5637, 13.7871,  3.1353,  4.1803],\n",
       "            [ 8.0842,  0.9610,  4.4694,  1.6417,  2.1619,  4.3157,  3.1321,  2.3484,\n",
       "              7.2567,  6.0916,  3.3121, 11.3438,  4.4653, 33.3787,  5.8795,  5.0003]],\n",
       "           device='cuda:0')},\n",
       "   5: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([ 0.0121, -0.1657, -0.1659,  0.0103, -0.0564, -0.0812, -0.2985, -0.0723,\n",
       "             0.2754, -0.1271,  0.0714,  0.0656,  0.0048, -0.1673,  0.0040,  0.2764],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0629, 0.1324, 0.1175, 0.2853, 0.1519, 0.1075, 0.3223, 0.0362, 0.3313,\n",
       "            0.1728, 0.4591, 0.5266, 0.3046, 0.2994, 0.1920, 0.3058],\n",
       "           device='cuda:0')},\n",
       "   6: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[ 5.9792e-02, -1.8799e-02,  1.0591e-01,  ...,  2.9568e-02,\n",
       "             -1.1529e-02,  1.4721e-02],\n",
       "            [-2.5428e-03, -6.8287e-02,  5.8526e-02,  ...,  4.9270e-01,\n",
       "             -1.1071e-01, -8.2775e-01],\n",
       "            [ 1.5465e-01, -5.2195e-02, -1.7035e-01,  ...,  7.8954e-04,\n",
       "             -1.4916e-02,  1.7785e-01],\n",
       "            ...,\n",
       "            [ 3.0538e-01, -1.8296e-01, -2.3747e-01,  ...,  8.0836e-02,\n",
       "             -1.2516e-01, -3.5157e-01],\n",
       "            [-5.0347e-02,  4.1128e-02,  2.0580e-01,  ..., -1.4169e-02,\n",
       "              5.5020e-02,  3.4861e-01],\n",
       "            [ 8.0160e-02,  2.2471e-03, -9.1275e-03,  ..., -4.1071e-02,\n",
       "              6.3996e-02,  7.3145e-02]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[0.2446, 0.1052, 0.7695,  ..., 0.5158, 0.1188, 1.1074],\n",
       "            [2.3733, 1.0988, 8.7806,  ..., 4.0930, 2.0138, 9.8886],\n",
       "            [0.5104, 0.1761, 1.6290,  ..., 0.9329, 0.5519, 2.5630],\n",
       "            ...,\n",
       "            [0.8429, 0.3409, 2.3192,  ..., 0.5766, 0.1888, 1.2004],\n",
       "            [0.2521, 0.1310, 1.8999,  ..., 0.9466, 0.2597, 1.8771],\n",
       "            [0.2407, 0.0487, 1.4057,  ..., 0.1893, 0.1788, 0.4691]],\n",
       "           device='cuda:0')},\n",
       "   7: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([ 1.4601e-02,  3.7028e-02,  6.9039e-04, -5.1996e-03, -7.6265e-02,\n",
       "             1.2700e-02, -6.4114e-02, -3.9723e-02, -9.9003e-03, -2.4697e-02,\n",
       "             1.0878e-04, -1.1126e-03,  6.6492e-03, -3.6483e-02,  3.2678e-02,\n",
       "            -9.5952e-02,  1.3065e-01,  4.4285e-02,  4.6954e-03, -1.7961e-02,\n",
       "             2.5203e-02, -1.6330e-03, -1.2476e-01, -1.6526e-02, -5.3104e-02,\n",
       "             4.5804e-02,  1.0495e-01,  1.2144e-02,  2.2233e-02, -8.5545e-03,\n",
       "             2.8124e-03,  1.9267e-02], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([2.8525e-02, 7.7886e-02, 1.2751e-04, 9.4535e-04, 2.5832e-01, 3.1245e-02,\n",
       "            1.1195e-02, 2.5106e-02, 2.8415e-02, 2.7292e-02, 1.1823e-05, 2.0406e-03,\n",
       "            5.3152e-02, 3.6966e-02, 1.9676e-02, 5.2813e-02, 3.4029e-01, 2.3262e-02,\n",
       "            2.9331e-02, 2.8332e-02, 8.5380e-03, 1.1946e-03, 1.9642e-01, 2.7809e-02,\n",
       "            4.8444e-02, 8.4389e-02, 1.9941e-01, 8.6973e-02, 4.5832e-02, 2.8793e-03,\n",
       "            1.8758e-02, 4.7910e-02], device='cuda:0')},\n",
       "   8: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([ 0.1906, -0.1851, -0.0739, -0.2110,  0.0966,  0.1702,  0.2677, -0.0360,\n",
       "             0.1816, -0.0451,  0.0954,  0.0172, -0.0327, -0.0724, -0.0038, -0.1180,\n",
       "            -0.2456,  0.2354,  0.2241,  0.0233,  0.2923, -0.0184,  0.1251,  0.0778,\n",
       "             0.0808, -0.1419, -0.0898, -0.1030,  0.0448,  0.0454,  0.0519, -0.0739],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.5051, 0.9964, 0.2839, 0.6029, 0.9678, 0.4943, 0.8413, 0.3502, 0.9182,\n",
       "            0.2906, 0.6919, 0.6383, 0.9032, 0.7048, 0.5739, 0.7509, 1.4192, 0.4578,\n",
       "            0.5778, 0.7809, 0.2995, 0.6344, 1.6333, 0.4457, 0.5606, 1.3549, 1.2611,\n",
       "            0.7262, 0.7173, 0.3225, 0.3932, 0.3544], device='cuda:0')},\n",
       "   9: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.1091,  0.0298,  0.0860, -0.0051,  0.0578, -0.0334,  0.0382,  0.0268,\n",
       "             0.0582, -0.0548,  0.0086, -0.0657,  0.0388,  0.0670, -0.0688,  0.0012,\n",
       "             0.0545, -0.0345,  0.0096,  0.0361,  0.0333, -0.0066, -0.0577, -0.0608,\n",
       "            -0.1009,  0.0159, -0.0161,  0.0513,  0.0382,  0.0383,  0.0298,  0.0568],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0585, 0.0441, 0.2930, 0.1814, 0.1251, 0.1597, 0.1243, 0.1605, 0.1981,\n",
       "            0.0943, 0.0266, 0.1207, 0.0778, 0.3079, 0.2783, 0.1845, 0.0629, 0.2698,\n",
       "            0.1494, 0.1461, 0.0843, 0.1417, 0.1170, 0.1722, 0.1111, 0.1940, 0.0524,\n",
       "            0.1312, 0.1463, 0.1129, 0.1043, 0.0501], device='cuda:0')},\n",
       "   10: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[-0.0136,  0.5738, -0.4419,  ...,  0.1175,  0.1741,  0.2381],\n",
       "            [ 0.0814,  0.2762, -0.0289,  ...,  0.3218, -0.1439,  0.3233],\n",
       "            [-0.1463,  0.3191, -0.1673,  ...,  0.2657,  0.1323,  0.0563],\n",
       "            ...,\n",
       "            [-0.2569,  0.0295, -0.0514,  ..., -0.2236,  0.3499, -0.5499],\n",
       "            [ 0.2091,  0.1528,  0.1215,  ..., -0.0034,  0.0116,  0.1092],\n",
       "            [-0.0258, -0.1036,  0.1084,  ...,  0.0130,  0.0057,  0.0239]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[2.0697, 5.2251, 1.7293,  ..., 4.4993, 4.7021, 4.3039],\n",
       "            [1.1004, 1.6385, 1.0034,  ..., 0.8504, 1.2558, 1.4514],\n",
       "            [0.4517, 0.6606, 0.4647,  ..., 0.6395, 0.9860, 0.3254],\n",
       "            ...,\n",
       "            [0.4901, 0.5210, 0.4647,  ..., 0.6626, 0.3393, 0.5731],\n",
       "            [2.3700, 2.5712, 3.2474,  ..., 2.8336, 3.2470, 2.6324],\n",
       "            [0.0917, 0.2081, 0.0879,  ..., 0.1120, 0.1524, 0.1009]],\n",
       "           device='cuda:0')},\n",
       "   11: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([ 0.0296,  0.0144, -0.0832, -0.1304, -0.0367,  0.0416,  0.0488, -0.0670,\n",
       "             0.0363,  0.0386,  0.0387, -0.1352, -0.0183, -0.1929,  0.1391,  0.0667,\n",
       "            -0.0087,  0.0929, -0.0334,  0.0250, -0.0748,  0.0063, -0.0565,  0.0527,\n",
       "             0.0080, -0.0626,  0.0432,  0.0591, -0.0709,  0.0450,  0.0113,  0.0030],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0920, 0.1512, 0.1039, 0.1790, 0.1118, 0.0347, 0.0583, 0.2391, 0.1925,\n",
       "            0.0318, 0.0157, 0.3565, 0.0988, 0.8971, 0.2924, 0.1984, 0.0129, 0.0562,\n",
       "            0.0888, 0.0430, 0.4856, 0.0917, 0.0440, 0.1099, 0.0475, 0.0685, 0.0563,\n",
       "            0.0677, 0.0974, 0.0156, 0.0450, 0.0134], device='cuda:0')},\n",
       "   12: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.2076,  0.0770,  0.0497,  0.0466, -0.1841,  0.0316, -0.0414, -0.0416,\n",
       "            -0.1023, -0.2413, -0.0315,  0.1003,  0.2132,  0.0277,  0.1450, -0.0851,\n",
       "             0.0733, -0.0504, -0.0721, -0.0076, -0.0607, -0.1228,  0.0792, -0.0543,\n",
       "             0.0363,  0.1399,  0.0053, -0.0416,  0.0777, -0.2001,  0.0526,  0.0004],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.4711, 0.5911, 0.3663, 0.4084, 0.0970, 0.3641, 0.5688, 0.3415, 0.5668,\n",
       "            0.2871, 0.2108, 0.8911, 0.4145, 1.1580, 0.3124, 0.4105, 0.2499, 0.1645,\n",
       "            0.2078, 0.2740, 0.4349, 0.4761, 0.2430, 0.2692, 0.2469, 0.2967, 0.8883,\n",
       "            0.4331, 0.2484, 0.6541, 0.5307, 0.1033], device='cuda:0')},\n",
       "   13: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.0705,  0.0057,  0.0270, -0.0111,  0.0638,  0.0121,  0.0485,  0.0301,\n",
       "             0.0135, -0.0435, -0.0325, -0.0581,  0.0621,  0.0677, -0.0246,  0.0273,\n",
       "             0.0458, -0.0490,  0.0281, -0.0089,  0.0178, -0.0062, -0.0217, -0.0155,\n",
       "            -0.0812,  0.0113,  0.0008,  0.0231,  0.0160,  0.0040,  0.0589,  0.0682],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0441, 0.0426, 0.1802, 0.1755, 0.0996, 0.0553, 0.1310, 0.1106, 0.1062,\n",
       "            0.0752, 0.0535, 0.1138, 0.0495, 0.2560, 0.2107, 0.2062, 0.0671, 0.2743,\n",
       "            0.1533, 0.0860, 0.0594, 0.1324, 0.0833, 0.1095, 0.0963, 0.1689, 0.0366,\n",
       "            0.1073, 0.0861, 0.1603, 0.1376, 0.0356], device='cuda:0')},\n",
       "   14: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[-0.0464,  0.2832, -0.2688,  ..., -0.1272, -0.0430,  0.2219],\n",
       "            [-0.0636,  0.4794, -0.3046,  ..., -0.2355,  0.1000,  0.2376],\n",
       "            [ 0.0251,  0.2411, -0.1362,  ..., -0.6913,  0.0397,  0.2976],\n",
       "            ...,\n",
       "            [ 0.1065, -0.1199,  0.0885,  ...,  0.1451, -0.0426,  0.0461],\n",
       "            [-0.0142,  0.0019, -0.0328,  ...,  0.0271,  0.0098,  0.0035],\n",
       "            [-0.0106, -0.0801,  0.0363,  ...,  0.1078,  0.1019, -0.0990]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.9036e+00, 1.8564e+00, 4.0585e-01,  ..., 4.6700e+00, 9.7498e-01,\n",
       "             1.4790e+00],\n",
       "            [9.6350e-01, 1.5335e+00, 4.4960e-01,  ..., 3.9164e+00, 8.4487e-01,\n",
       "             1.3148e+00],\n",
       "            [1.9196e+00, 1.2490e+00, 4.4661e-01,  ..., 5.1860e+00, 1.0242e+00,\n",
       "             9.9995e-01],\n",
       "            ...,\n",
       "            [6.3817e-01, 3.0778e-01, 1.0388e-01,  ..., 7.2273e-01, 2.5227e-01,\n",
       "             2.7674e-01],\n",
       "            [3.0910e-02, 5.3432e-02, 5.0267e-03,  ..., 2.1826e-01, 2.6801e-02,\n",
       "             2.0116e-02],\n",
       "            [2.2142e-01, 3.1707e-01, 8.4554e-02,  ..., 5.4031e-01, 3.1531e-01,\n",
       "             2.5797e-01]], device='cuda:0')},\n",
       "   15: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.0595, -0.0764, -0.0988, -0.0872, -0.1196,  0.0359,  0.0719, -0.0556,\n",
       "             0.0021,  0.0105,  0.1426, -0.0422,  0.0293, -0.0572,  0.0772,  0.0343,\n",
       "            -0.0058,  0.1066, -0.0590,  0.0417, -0.0229, -0.0717, -0.0390,  0.0183,\n",
       "             0.0376, -0.2812,  0.0715,  0.0685, -0.0186,  0.0514, -0.0076,  0.0003],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.1753, 0.1780, 0.1620, 0.0992, 0.1666, 0.0241, 0.1694, 0.0722, 0.0212,\n",
       "            0.0204, 0.0990, 0.0785, 0.0121, 0.2853, 0.0863, 0.0378, 0.0462, 0.2292,\n",
       "            0.1084, 0.0703, 0.0191, 0.3572, 0.0158, 0.0448, 0.1020, 0.7531, 0.1309,\n",
       "            0.0918, 0.0792, 0.0187, 0.0010, 0.0281], device='cuda:0')},\n",
       "   16: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.1717, -0.1197,  0.1125,  0.0770,  0.0536,  0.0307,  0.0035, -0.0172,\n",
       "             0.0038,  0.0887, -0.0631,  0.0041,  0.0366, -0.2980, -0.0256, -0.0654,\n",
       "             0.1149,  0.1998, -0.0004,  0.0216, -0.0459,  0.0264,  0.0052,  0.1177,\n",
       "             0.1055,  0.2662,  0.0130, -0.0829, -0.1379, -0.1243,  0.0087, -0.0669],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.3081, 0.1036, 0.2240, 0.1744, 0.1028, 0.0966, 0.1517, 0.1275, 0.0437,\n",
       "            0.0685, 0.0874, 0.0486, 0.0427, 0.2757, 0.1469, 0.1567, 0.1665, 0.1879,\n",
       "            0.1147, 0.0929, 0.0437, 0.2612, 0.0781, 0.1715, 0.1440, 0.4948, 0.0450,\n",
       "            0.1440, 0.0970, 0.0767, 0.0069, 0.1195], device='cuda:0')},\n",
       "   17: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.0501, -0.0440,  0.0272,  0.0299,  0.0504, -0.0062,  0.0350,  0.0281,\n",
       "            -0.0066, -0.0106, -0.0107, -0.0008,  0.0386,  0.0405, -0.0185,  0.0044,\n",
       "             0.0613,  0.0171,  0.0064, -0.0051,  0.0318, -0.0014, -0.0106, -0.0014,\n",
       "            -0.0921, -0.0134,  0.0010, -0.0146,  0.0195,  0.0396,  0.0021,  0.0409],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0320, 0.0342, 0.1687, 0.1629, 0.0651, 0.0313, 0.0954, 0.1002, 0.0340,\n",
       "            0.0422, 0.0215, 0.0646, 0.0378, 0.2309, 0.2130, 0.1111, 0.0558, 0.1847,\n",
       "            0.1346, 0.0495, 0.0706, 0.1324, 0.0746, 0.0732, 0.0720, 0.1624, 0.0263,\n",
       "            0.1003, 0.0820, 0.0628, 0.0100, 0.0202], device='cuda:0')},\n",
       "   18: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[-6.8358e-02, -6.6247e-02,  1.0170e-01, -3.0497e-02, -1.5583e-01,\n",
       "             -6.4771e-02,  7.3869e-02, -3.6892e-02, -1.8548e-01, -3.8749e-02,\n",
       "              5.2525e-02,  1.2594e-01,  2.3234e-01,  1.4266e-01, -4.3549e-02,\n",
       "             -1.0990e-02, -1.3039e-01,  1.7889e-01, -4.3129e-02, -8.6869e-02,\n",
       "              2.2048e-02, -7.3214e-03, -5.8666e-02,  1.0333e-01, -1.6138e-01,\n",
       "              3.3231e-02,  2.0441e-01, -1.1632e-01, -3.1618e-02,  1.0356e-01,\n",
       "             -4.7561e-02,  9.4766e-03],\n",
       "            [ 1.3565e-02,  5.1212e-02,  2.4154e-02,  6.6220e-02,  3.1448e-02,\n",
       "              5.0764e-03,  7.2363e-02,  1.0833e-01,  1.1876e-01,  1.4753e-02,\n",
       "              2.0362e-02, -4.6240e-03, -8.9832e-02, -1.3458e-01,  4.4248e-02,\n",
       "             -2.7493e-02, -1.7507e-02, -1.1701e-02,  5.9858e-02,  3.8740e-02,\n",
       "             -2.6499e-02, -3.5441e-02,  1.5111e-02, -7.8724e-02,  8.9832e-02,\n",
       "              1.0230e-01, -1.3117e-01,  4.9260e-02,  8.6979e-02, -3.9693e-02,\n",
       "             -4.1046e-02,  1.0022e-01],\n",
       "            [-2.0810e-01,  5.0730e-02, -8.2126e-02, -1.2825e-01, -6.3298e-01,\n",
       "             -5.8704e-01, -1.8728e-01, -1.0503e-02,  9.9436e-02, -1.1069e-01,\n",
       "              5.2562e-01,  1.7039e-01, -2.6170e-01, -2.2803e-01, -2.1163e-01,\n",
       "              3.9449e-01,  1.4527e-01, -4.0008e-01, -6.7125e-03, -6.5444e-03,\n",
       "             -1.1292e-01,  1.2734e-01,  3.3105e-01, -5.1598e-01,  6.3744e-02,\n",
       "              5.9044e-01, -6.4953e-01,  1.2443e-01, -3.4108e-02, -6.3064e-01,\n",
       "              1.5579e-01, -5.2218e-01],\n",
       "            [ 1.0171e-01,  1.0378e-02,  1.5294e-01,  3.4467e-02,  1.0046e-01,\n",
       "             -8.5990e-02,  1.4650e-01,  1.4562e-01,  5.5021e-02,  7.3390e-04,\n",
       "             -5.6922e-02,  4.0512e-02,  4.5459e-02, -1.1458e-01, -1.2867e-01,\n",
       "              5.6924e-02,  1.1930e-01,  1.3415e-01,  1.0826e-02, -7.1680e-03,\n",
       "              3.1477e-02, -1.2880e-02,  7.8773e-02,  9.3919e-02, -1.9392e-01,\n",
       "              1.9443e-01, -1.6027e-01,  1.3365e-02,  6.4027e-02, -4.8812e-02,\n",
       "             -7.6597e-02,  1.1441e-01],\n",
       "            [ 8.2601e-02,  4.9566e-02,  2.3961e-02,  7.6303e-02,  3.6042e-01,\n",
       "              2.4027e-01,  1.0300e-01, -7.1513e-03,  4.1090e-03,  8.8451e-02,\n",
       "             -1.9260e-01, -1.4572e-01,  1.3156e-02,  5.3950e-02,  1.3237e-01,\n",
       "             -2.3677e-01, -5.5926e-02,  8.1345e-02, -1.7416e-02,  3.2938e-02,\n",
       "             -2.5341e-03, -9.2158e-02, -1.6901e-01,  2.0047e-01, -1.3085e-02,\n",
       "             -3.2193e-01,  1.9533e-01, -2.9817e-02, -2.7023e-03,  2.0837e-01,\n",
       "             -7.5546e-02,  2.3285e-01],\n",
       "            [ 6.7787e-02,  6.0874e-02,  1.2890e-01, -7.0057e-02, -3.3933e-02,\n",
       "             -2.1674e-01, -2.5187e-01,  8.2797e-02, -1.1136e-01, -1.2617e-01,\n",
       "             -1.2460e-01,  1.0633e-02, -9.2234e-02, -2.3290e-01, -7.5323e-02,\n",
       "              2.6865e-01, -8.1426e-02, -1.0576e-01, -4.3013e-03, -2.6311e-03,\n",
       "             -3.5780e-02, -1.7038e-03,  2.9950e-01, -1.6545e-01,  1.4904e-02,\n",
       "              5.9589e-02, -4.4677e-01, -2.8498e-02, -9.1281e-02, -6.9709e-02,\n",
       "             -7.4600e-03, -8.0021e-02],\n",
       "            [ 1.5930e-01, -7.0336e-02,  1.8166e-01, -7.2676e-02, -6.3043e-02,\n",
       "             -1.2275e-01, -1.2853e-01,  2.2155e-01, -2.7861e-02, -1.6673e-01,\n",
       "             -2.5785e-01,  1.3127e-01,  1.0238e-01, -2.1835e-01, -7.6430e-02,\n",
       "              4.1674e-01, -4.0959e-02,  1.2704e-01,  4.8750e-02,  1.1645e-02,\n",
       "             -2.8079e-02,  1.3497e-01,  3.2395e-01,  1.3874e-02, -5.8880e-02,\n",
       "              2.2025e-01, -1.8110e-01,  7.8442e-02, -6.8904e-02,  1.6436e-01,\n",
       "             -7.5313e-02,  3.8713e-02],\n",
       "            [-7.5983e-02, -3.1254e-01,  7.8013e-02, -2.0581e-02, -3.0099e-01,\n",
       "             -1.2075e-02,  1.4734e-01, -8.4758e-02, -3.0874e-01, -6.7962e-02,\n",
       "              4.5023e-03,  3.2982e-01,  5.8398e-01,  3.7644e-01, -1.7645e-01,\n",
       "             -7.8152e-03, -4.5847e-02,  4.5799e-01, -4.3110e-02, -1.1161e-01,\n",
       "              1.4233e-01,  3.7560e-02, -1.6771e-01,  3.6639e-01, -2.7646e-01,\n",
       "              1.7290e-01,  4.7075e-01, -2.1690e-01,  8.2260e-02,  1.7582e-01,\n",
       "              2.7479e-03, -3.9116e-02],\n",
       "            [ 5.9365e-01, -1.5477e-02,  1.3665e-01, -1.3334e-02,  6.7303e-01,\n",
       "             -6.1397e-02,  1.2512e-01, -1.1100e-01,  8.1415e-02,  2.7922e-01,\n",
       "             -3.7851e-01, -2.3020e-01,  1.5244e-02,  1.8552e-02, -3.1360e-01,\n",
       "             -1.3663e-01,  4.4391e-01,  4.5644e-03,  5.8283e-02,  1.4660e-01,\n",
       "              1.5102e-01, -1.3648e-01,  2.4293e-03,  4.2950e-01, -4.5856e-01,\n",
       "             -2.6922e-01, -2.4198e-01, -6.3591e-02,  2.0117e-01, -2.8431e-01,\n",
       "              4.1479e-02, -1.4733e-01],\n",
       "            [ 2.4349e-01, -3.2372e-02,  6.9059e-02, -2.6386e-02,  3.7612e-01,\n",
       "              6.3451e-02, -7.3042e-03, -1.8428e-04, -4.1314e-02,  1.1400e-01,\n",
       "             -2.2341e-01, -1.3013e-01, -3.4063e-03, -1.3454e-02, -1.8066e-01,\n",
       "             -1.5794e-02,  2.9722e-01,  1.4539e-02,  1.4707e-02,  1.0136e-02,\n",
       "              1.4579e-01, -1.9584e-02,  6.5304e-02,  1.5166e-01, -2.6597e-01,\n",
       "             -1.1840e-01, -1.0033e-01, -3.8433e-02, -1.1678e-02, -8.3803e-02,\n",
       "              5.6235e-02, -3.0668e-02],\n",
       "            [ 2.5383e-02, -4.7118e-02,  3.4473e-02, -1.0360e-02,  5.4232e-02,\n",
       "              1.7921e-03,  1.6281e-03, -4.2580e-02, -5.0656e-02,  3.0548e-02,\n",
       "             -2.4005e-02, -9.2660e-03,  5.1502e-02,  6.6122e-02, -7.9608e-02,\n",
       "             -2.5684e-02,  5.8985e-02,  4.3792e-02, -3.4487e-02, -1.0467e-02,\n",
       "              5.8415e-02, -1.9227e-02,  7.3113e-04,  9.9873e-02, -1.1289e-01,\n",
       "             -1.1753e-03,  1.3883e-02, -6.3595e-02, -1.8358e-03, -3.4202e-02,\n",
       "              1.7508e-02, -2.8426e-02],\n",
       "            [ 4.5563e-01,  4.1502e-02,  1.1937e-01,  3.2648e-02,  8.6841e-01,\n",
       "              7.3262e-02,  6.2494e-02, -1.5228e-01, -4.8223e-02,  4.4181e-01,\n",
       "             -3.5237e-01, -2.2926e-01,  5.6351e-02,  1.4654e-01, -2.8514e-01,\n",
       "             -2.4757e-01,  6.0995e-01,  1.3362e-02,  3.9890e-02,  1.2049e-01,\n",
       "              2.4323e-01, -5.4719e-03, -2.2331e-03,  4.3886e-01, -6.2337e-01,\n",
       "             -3.7556e-01, -1.7290e-02, -2.3062e-02,  1.3758e-01, -2.5147e-01,\n",
       "              1.4116e-01, -4.1877e-02],\n",
       "            [-5.5833e-01, -8.6162e-02, -2.5793e-01, -1.1834e-01, -1.0035e+00,\n",
       "              2.3548e-02, -3.5267e-01,  1.5385e-01, -7.2150e-04, -4.3008e-01,\n",
       "              3.3063e-01,  2.6637e-01, -8.7058e-02, -1.7559e-01,  3.3383e-01,\n",
       "              2.7718e-01, -6.5060e-01, -1.1100e-01, -1.7921e-02, -1.4515e-01,\n",
       "             -2.1721e-01,  1.3426e-01,  5.7040e-02, -6.7767e-01,  7.2419e-01,\n",
       "              3.7698e-01,  9.1775e-02,  7.0746e-02, -2.1774e-01,  2.3442e-01,\n",
       "             -4.4302e-02, -4.5956e-02],\n",
       "            [ 2.6927e-01, -6.2801e-02,  3.6163e-02,  5.1460e-02,  2.9417e-01,\n",
       "              9.3992e-02,  3.8428e-02, -7.6364e-02, -1.3859e-02,  1.9999e-01,\n",
       "             -1.4382e-01, -8.6075e-02,  1.4615e-01,  1.2347e-01, -2.4273e-01,\n",
       "             -1.3924e-01,  2.6661e-01,  7.5603e-02,  4.9702e-02,  3.4073e-02,\n",
       "              1.8086e-01,  8.8498e-03, -6.5679e-02,  2.6266e-01, -3.5340e-01,\n",
       "             -1.1224e-01,  1.7133e-01, -1.6409e-02,  1.3470e-01, -1.3300e-01,\n",
       "              1.2405e-01, -3.7604e-02],\n",
       "            [ 1.0403e-01, -1.5193e-02,  4.4674e-02,  5.8147e-02,  2.7011e-01,\n",
       "              2.8341e-01,  8.3922e-02,  2.3391e-02, -4.5008e-02,  5.0689e-02,\n",
       "             -2.4703e-01, -5.6090e-02,  1.4902e-01,  1.0351e-01,  1.0367e-01,\n",
       "             -1.5799e-01, -8.0436e-02,  1.9982e-01,  1.5064e-02,  1.1418e-02,\n",
       "              5.0392e-02, -3.5070e-02, -1.4851e-01,  2.5108e-01, -2.4910e-02,\n",
       "             -2.5887e-01,  3.3844e-01, -3.7036e-02,  1.7941e-02,  3.2372e-01,\n",
       "             -6.9247e-02,  2.5059e-01],\n",
       "            [ 1.4474e-01, -9.8805e-02, -2.7970e-02,  6.2879e-02,  4.2963e-01,\n",
       "             -1.1439e-02,  9.5164e-02, -1.7618e-01,  1.9559e-02,  3.0733e-01,\n",
       "             -7.9111e-02, -1.4755e-01,  4.8180e-02,  2.0224e-01, -3.3563e-01,\n",
       "             -2.1898e-01,  4.1170e-01,  6.6050e-02, -1.3626e-02,  1.4385e-01,\n",
       "              2.4306e-01, -1.5572e-01, -3.6101e-02,  2.5496e-01, -3.6212e-01,\n",
       "             -4.7805e-02, -1.1621e-01, -1.6273e-01,  1.4577e-01, -3.6874e-01,\n",
       "              1.2979e-01, -1.5865e-01]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[2.8047e-01, 3.0663e-01, 1.0722e-01, 2.0569e-01, 4.1216e-01, 1.7329e-01,\n",
       "             2.5072e-01, 1.2308e-01, 3.9145e-01, 1.5904e-01, 1.3586e-01, 1.5310e-01,\n",
       "             4.4634e-01, 2.1066e-01, 1.3864e-01, 2.9030e-01, 2.0269e-01, 2.6176e-01,\n",
       "             1.9241e-01, 2.6252e-01, 1.6463e-01, 8.9420e-02, 4.3339e-01, 3.4014e-01,\n",
       "             2.4103e-01, 1.4745e-01, 4.2307e-01, 2.1955e-01, 1.1017e-01, 4.1989e-01,\n",
       "             1.0617e-01, 1.2930e-01],\n",
       "            [4.6195e-01, 4.8485e-01, 1.8583e-01, 3.3478e-01, 8.1038e-01, 3.3777e-01,\n",
       "             2.2090e-01, 2.8689e-01, 1.9519e-01, 1.8833e-01, 2.6167e-01, 1.9234e-01,\n",
       "             2.8862e-01, 1.3174e-01, 2.8890e-01, 3.6083e-01, 4.5814e-01, 1.7472e-01,\n",
       "             2.3895e-01, 2.1974e-01, 1.8811e-01, 3.2294e-01, 3.3350e-01, 4.5570e-01,\n",
       "             3.3338e-01, 1.7255e-01, 3.8843e-01, 2.8143e-01, 1.6517e-01, 4.3013e-01,\n",
       "             1.6832e-01, 1.9787e-01],\n",
       "            [2.1514e+01, 5.8136e+00, 3.7795e+00, 6.4996e+00, 3.9687e+01, 1.2307e+01,\n",
       "             5.1768e+00, 3.4390e+00, 5.4180e+00, 3.8658e+00, 1.4564e+01, 3.2830e+00,\n",
       "             4.1360e+00, 1.0119e+01, 1.2053e+01, 6.0653e+00, 3.7237e+01, 3.7393e+00,\n",
       "             4.8097e+00, 4.0912e+00, 1.8977e+00, 4.2689e+00, 5.8127e+00, 1.1371e+01,\n",
       "             1.2474e+01, 5.2427e+00, 4.2039e+01, 3.9486e+00, 6.5363e+00, 2.2071e+01,\n",
       "             2.2421e+00, 7.7604e+00],\n",
       "            [2.7959e-01, 2.5063e-01, 2.3429e-01, 2.5068e-01, 5.0966e-01, 2.0301e-01,\n",
       "             2.1356e-01, 3.0752e-01, 1.9208e-01, 1.4976e-01, 1.9143e-01, 1.0834e-01,\n",
       "             1.3198e-01, 1.4658e-01, 2.3069e-01, 2.9346e-01, 4.1829e-01, 1.5783e-01,\n",
       "             1.6908e-01, 1.4789e-01, 1.5262e-01, 1.9354e-01, 3.0388e-01, 3.5293e-01,\n",
       "             3.1709e-01, 2.2741e-01, 3.8338e-01, 1.9028e-01, 1.6866e-01, 2.7531e-01,\n",
       "             1.5270e-01, 1.7278e-01],\n",
       "            [4.0674e+00, 1.0354e+00, 7.0920e-01, 1.2034e+00, 7.4644e+00, 2.3493e+00,\n",
       "             9.6917e-01, 6.1755e-01, 9.6565e-01, 6.8946e-01, 2.7322e+00, 5.6263e-01,\n",
       "             6.0971e-01, 1.9086e+00, 2.3028e+00, 1.1024e+00, 7.1146e+00, 5.6274e-01,\n",
       "             8.7010e-01, 7.3080e-01, 3.1878e-01, 7.6297e-01, 1.0685e+00, 2.1138e+00,\n",
       "             2.4114e+00, 9.6132e-01, 7.8473e+00, 6.8185e-01, 1.2172e+00, 4.2728e+00,\n",
       "             4.1671e-01, 1.4914e+00],\n",
       "            [3.7073e-01, 5.6851e-01, 2.9885e-01, 4.6116e-01, 2.3644e+00, 1.3777e+00,\n",
       "             5.0608e-01, 4.6956e-01, 7.0639e-01, 5.9024e-01, 7.7926e-01, 5.8038e-01,\n",
       "             8.5786e-01, 4.6011e-01, 8.3439e-01, 6.7344e-01, 9.9727e-01, 6.4570e-01,\n",
       "             3.3533e-01, 5.8167e-01, 1.6335e-01, 6.5719e-01, 7.0274e-01, 5.3735e-01,\n",
       "             8.0655e-01, 3.2314e-01, 3.0998e+00, 5.3803e-01, 5.4378e-01, 2.4595e+00,\n",
       "             2.3931e-01, 7.0056e-01],\n",
       "            [1.7190e-01, 2.2816e-01, 1.8145e-01, 2.6564e-01, 6.4732e-01, 4.0009e-01,\n",
       "             2.4720e-01, 2.5562e-01, 2.8938e-01, 3.1383e-01, 3.1723e-01, 1.8100e-01,\n",
       "             2.4244e-01, 1.6985e-01, 3.0676e-01, 4.2529e-01, 3.3939e-01, 2.6291e-01,\n",
       "             2.1039e-01, 2.4835e-01, 1.4065e-01, 2.5014e-01, 2.5691e-01, 3.2409e-01,\n",
       "             3.6629e-01, 2.3136e-01, 6.5167e-01, 2.6564e-01, 2.5261e-01, 7.9760e-01,\n",
       "             1.5482e-01, 2.7276e-01],\n",
       "            [4.7481e-01, 1.0837e+00, 5.0144e-01, 5.3415e-01, 9.3970e-01, 9.2562e-01,\n",
       "             8.7443e-01, 6.8012e-01, 1.1376e+00, 6.8285e-01, 1.0572e+00, 1.2066e+00,\n",
       "             3.0174e+00, 9.0050e-01, 8.1719e-01, 1.6266e+00, 5.0471e-01, 2.1822e+00,\n",
       "             4.9865e-01, 6.6274e-01, 5.1853e-01, 1.4200e+00, 6.3218e-01, 1.1091e+00,\n",
       "             6.2184e-01, 6.4133e-01, 3.7629e+00, 8.7895e-01, 3.9641e-01, 1.5836e+00,\n",
       "             3.5982e-01, 4.2066e-01],\n",
       "            [6.4490e+00, 1.5404e+00, 8.5082e-01, 2.2792e+00, 1.3147e+01, 6.9344e-01,\n",
       "             1.8091e+00, 6.9838e-01, 1.6558e+00, 1.2366e+00, 3.7157e+00, 6.1351e-01,\n",
       "             8.3492e-01, 2.0681e+00, 1.7096e+00, 1.6397e+00, 1.0856e+01, 5.6707e-01,\n",
       "             1.2434e+00, 1.2435e+00, 4.8271e-01, 1.0311e+00, 1.7209e+00, 4.2346e+00,\n",
       "             1.5505e+00, 1.5771e+00, 8.8511e+00, 1.0636e+00, 1.4302e+00, 1.9482e+00,\n",
       "             5.7345e-01, 7.9723e-01],\n",
       "            [2.1580e+00, 6.0375e-01, 2.4355e-01, 9.0824e-01, 4.1424e+00, 2.1758e-01,\n",
       "             5.6465e-01, 2.9428e-01, 3.5196e-01, 3.5623e-01, 1.3363e+00, 1.9256e-01,\n",
       "             1.9718e-01, 4.6394e-01, 6.1270e-01, 7.4614e-01, 3.2525e+00, 1.4858e-01,\n",
       "             3.7166e-01, 4.4644e-01, 2.6815e-01, 3.0487e-01, 5.4920e-01, 1.5530e+00,\n",
       "             5.1281e-01, 4.1878e-01, 1.8574e+00, 3.4389e-01, 2.5753e-01, 4.4518e-01,\n",
       "             2.5911e-01, 2.2315e-01],\n",
       "            [5.8579e-02, 5.8392e-02, 2.0650e-02, 4.0597e-02, 1.0029e-01, 5.2345e-02,\n",
       "             3.1090e-02, 2.7259e-02, 4.1981e-02, 3.3004e-02, 3.3716e-02, 3.9306e-02,\n",
       "             7.7990e-02, 2.8664e-02, 3.2937e-02, 5.5560e-02, 4.1977e-02, 5.8263e-02,\n",
       "             3.4436e-02, 4.3510e-02, 2.8512e-02, 4.2755e-02, 4.1192e-02, 6.2802e-02,\n",
       "             4.7763e-02, 2.3119e-02, 6.8075e-02, 3.7818e-02, 1.9779e-02, 7.0209e-02,\n",
       "             2.0916e-02, 2.4740e-02],\n",
       "            [7.4420e+00, 2.5933e+00, 1.2712e+00, 3.5728e+00, 1.3979e+01, 1.0614e+00,\n",
       "             2.5278e+00, 1.2384e+00, 2.3192e+00, 2.0788e+00, 3.8484e+00, 9.5169e-01,\n",
       "             1.3344e+00, 1.6995e+00, 2.4350e+00, 2.6928e+00, 1.2412e+01, 7.0073e-01,\n",
       "             1.6962e+00, 2.0831e+00, 1.1775e+00, 1.3441e+00, 2.1627e+00, 5.2894e+00,\n",
       "             2.2566e+00, 1.5625e+00, 7.1065e+00, 1.6854e+00, 1.7724e+00, 2.0739e+00,\n",
       "             1.0432e+00, 1.0558e+00],\n",
       "            [1.5053e+01, 3.8710e+00, 1.5977e+00, 5.6274e+00, 2.9407e+01, 2.5445e+00,\n",
       "             4.2279e+00, 1.2449e+00, 3.7747e+00, 2.8698e+00, 8.5328e+00, 1.1732e+00,\n",
       "             1.9191e+00, 4.4722e+00, 5.0109e+00, 3.9681e+00, 2.5138e+01, 1.3095e+00,\n",
       "             3.5066e+00, 3.1255e+00, 1.4362e+00, 2.1315e+00, 4.1050e+00, 9.8349e+00,\n",
       "             4.0446e+00, 3.3986e+00, 1.8632e+01, 2.5199e+00, 3.7019e+00, 6.6406e+00,\n",
       "             1.5277e+00, 3.0338e+00],\n",
       "            [3.2772e+00, 1.1837e+00, 3.2764e-01, 1.6870e+00, 8.9706e+00, 4.6724e-01,\n",
       "             1.1968e+00, 3.5071e-01, 1.0426e+00, 8.5907e-01, 1.9790e+00, 4.3828e-01,\n",
       "             6.7036e-01, 8.5300e-01, 9.7674e-01, 1.0669e+00, 7.0561e+00, 3.6984e-01,\n",
       "             8.4387e-01, 9.8536e-01, 4.7137e-01, 6.4017e-01, 1.5011e+00, 2.4263e+00,\n",
       "             6.9810e-01, 8.2345e-01, 5.3850e+00, 8.1562e-01, 7.3930e-01, 1.0751e+00,\n",
       "             5.5478e-01, 5.3945e-01],\n",
       "            [4.6889e+00, 1.2408e+00, 8.1293e-01, 1.3970e+00, 8.6400e+00, 2.6163e+00,\n",
       "             1.1177e+00, 7.2337e-01, 1.1597e+00, 8.1879e-01, 3.1468e+00, 6.8841e-01,\n",
       "             8.4818e-01, 2.1994e+00, 2.5938e+00, 1.2535e+00, 8.0585e+00, 7.6276e-01,\n",
       "             1.0296e+00, 8.6452e-01, 4.0611e-01, 8.9067e-01, 1.2499e+00, 2.4506e+00,\n",
       "             2.6721e+00, 1.1365e+00, 9.1426e+00, 8.2514e-01, 1.4034e+00, 4.7398e+00,\n",
       "             4.7915e-01, 1.6685e+00],\n",
       "            [4.1804e-01, 4.2337e-01, 2.1564e-01, 3.5726e-01, 1.2736e+00, 4.0610e-01,\n",
       "             3.0651e-01, 2.1761e-01, 4.9222e-01, 4.5411e-01, 3.3130e-01, 3.8604e-01,\n",
       "             5.3576e-01, 1.5700e-01, 3.2533e-01, 6.1746e-01, 5.8149e-01, 3.8829e-01,\n",
       "             2.5817e-01, 4.2037e-01, 1.6168e-01, 4.0374e-01, 1.6974e-01, 4.3870e-01,\n",
       "             4.1397e-01, 1.7199e-01, 6.0413e-01, 2.4701e-01, 2.7144e-01, 8.9782e-01,\n",
       "             1.3915e-01, 2.0105e-01]], device='cuda:0')},\n",
       "   19: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([-0.0538,  0.0330,  0.0125,  0.0376,  0.0112,  0.0324, -0.0140, -0.1247,\n",
       "             0.0637,  0.0496,  0.0059,  0.0714, -0.0774,  0.0435, -0.0153,  0.0464],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0511, 0.0653, 0.5026, 0.0572, 0.0837, 0.1049, 0.0652, 0.2301, 0.1507,\n",
       "            0.0632, 0.0091, 0.3117, 0.3663, 0.1238, 0.1064, 0.0621],\n",
       "           device='cuda:0')},\n",
       "   20: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([[ 0.2155,  0.0219,  0.6989,  0.1038, -1.4459, -0.2474, -0.1981,  0.3265,\n",
       "             -0.7326, -0.4730, -0.0991, -0.4640, -0.5516, -0.3642,  0.4768, -0.3979]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[  4.7586,   4.5258, 182.6070,   5.6850, 128.9480,   6.1165,   5.7181,\n",
       "               6.8561,  12.5561,   3.1641,   4.5178,   3.1896,  21.0003,   3.9468,\n",
       "             154.2170,   4.2624]], device='cuda:0')},\n",
       "   21: {'step': tensor(1547768.),\n",
       "    'exp_avg': tensor([0.0332], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([6.2114], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 1.128543672429847e-05,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.001,\n",
       "    'amsgrad': False,\n",
       "    'initial_lr': 1e-05,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17,\n",
       "     18,\n",
       "     19,\n",
       "     20,\n",
       "     21]}]},\n",
       " 'sched_dict': {'max_lrs': [0.0001],\n",
       "  'total_size': 4000.0,\n",
       "  'step_ratio': 0.5,\n",
       "  'mode': 'triangular',\n",
       "  'gamma': 1.0,\n",
       "  'scale_fn': <bound method CyclicLR._triangular_scale_fn of <torch.optim.lr_scheduler.CyclicLR object at 0x7f134e3a7f40>>,\n",
       "  'scale_mode': 'cycle',\n",
       "  'cycle_momentum': False,\n",
       "  'base_lrs': [1e-05],\n",
       "  'last_epoch': 28.56526053996637,\n",
       "  '_step_count': 63,\n",
       "  'verbose': False,\n",
       "  '_get_lr_called_within_step': False,\n",
       "  '_last_lr': [1.128543672429847e-05]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_restored_new = utils.load_checkpoint(restore_ckpt, torch_model)\n",
    "param_restored_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the C++ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the C++ GraphMetNetwork model\n",
    "cmodel = GraphMetNetwork()\n",
    "\n",
    "# Load the weights\n",
    "cmodel.load_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_emb_cont_weights = param_restored_new['state_dict']['graphnet.embed_continuous.0.weight'].cpu().numpy()\n",
    "torch_emb_cont_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmodel_emb_cont_weights = cmodel.get_graphmet_embed_continuous_0_weight()\n",
    "cmodel_emb_cont_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51976335  0.29137233 -0.01950876  0.3422203  -0.22453895  0.18464667]\n",
      " [-0.41697326 -0.19378653 -0.2800268  -0.03558999 -0.16028096  0.1395752 ]\n",
      " [-0.1805233  -0.11106941 -0.23513117 -0.11494771 -0.13471612 -0.46705556]\n",
      " [-0.09102532  0.03195464 -0.11112893  0.07975572  0.18790151  0.36718494]\n",
      " [-0.63014483 -0.1793874  -0.166681   -0.14576283  0.20136194 -0.3199493 ]\n",
      " [ 0.3729181  -0.03066996  0.02352745 -0.00087973  0.23562688 -0.4000545 ]\n",
      " [ 0.47255328 -0.05097763 -0.1412205   0.17181246 -0.11328534  0.17674764]\n",
      " [ 0.04552776 -0.01817972  0.04870505  0.19884565  0.23553249  0.29376933]\n",
      " [-0.45972535 -0.18024738 -0.37173915 -0.14721555 -0.26793975  0.32831663]\n",
      " [ 0.12318032 -0.33687368 -0.20999411 -0.17968899 -0.00177267 -0.00941435]\n",
      " [ 0.17154491 -0.14698578  0.14260884  0.03123299  0.25386858  0.00154118]\n",
      " [-0.3558818   0.091422    0.35282034  0.03867797 -0.09918415 -0.10135012]\n",
      " [ 0.06261277 -0.33330274 -0.33637494  0.2582759  -0.22359034  0.30760753]\n",
      " [-0.33064967  0.05518911 -0.15718341 -0.37711817  0.01571205 -0.198672  ]\n",
      " [-0.5701746   0.00181492 -0.01133007  0.05618472  0.05089286  0.225154  ]\n",
      " [-0.17142372 -0.17767563 -0.08171677  0.42331338  0.22421613  0.02002591]]\n"
     ]
    }
   ],
   "source": [
    "print(torch_emb_cont_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01408479  0.26224014  0.21124163 -0.02148151 -0.27710617 -0.18009436]\n",
      " [-0.11469425 -0.16827478  0.25944638  0.03087053  0.10644519 -0.3335978 ]\n",
      " [-0.2733658   0.1272415  -0.26642194 -0.09995878  0.01028038  0.322061  ]\n",
      " [-0.15765736  0.17464443 -0.2051494   0.11367632 -0.29654217  0.11224843]\n",
      " [-0.24401419 -0.16353707  0.2782284  -0.01478     0.17794731 -0.11090042]\n",
      " [-0.2502501  -0.15644376  0.28004238 -0.02011693  0.21282925 -0.12474898]\n",
      " [-0.2524805  -0.16291493  0.28042853  0.01157601  0.21667488 -0.11200128]\n",
      " [-0.20589809  0.10273653  0.06480501  0.11469385  0.16831794  0.02854833]\n",
      " [-0.31383845  0.13041887 -0.1979931   0.58252996 -0.02516119  0.156358  ]\n",
      " [-0.22235836  0.1070975   0.10644051  0.01248249  0.1654896  -0.20216064]\n",
      " [-0.29422224 -0.03631451  0.04636873  0.06164292  0.26499832  0.6169511 ]\n",
      " [-0.2752517  -0.00498366  0.08971923 -0.14684242 -0.12780145  0.62608856]\n",
      " [ 0.11506677 -0.57081324 -0.34112072  0.00434716  0.07189704 -0.086274  ]\n",
      " [-0.317476    0.11207171 -0.20900275  0.00556385  0.06112197  0.35261044]\n",
      " [-0.24850106  0.11974397 -0.25856695 -0.05103826  0.01901265  0.29262614]\n",
      " [-0.29331803 -0.03708971  0.04487672  0.07352564  0.27557245  0.61470985]]\n"
     ]
    }
   ],
   "source": [
    "print(cmodel_emb_cont_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(np\u001b[38;5;241m.\u001b[39mallclose(torch_emb_cont_weights, cmodel_emb_cont_weights, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(np.allclose(torch_emb_cont_weights, cmodel_emb_cont_weights, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch_model(x_cont_test, x_cat_test, edge_index_test, batch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the C++ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmodel.GraphMetNetworkLayers(x_cont, x_cat, batch, num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_x_cont = cmodel.get_x_cont()\n",
    "c_x_cat = cmodel.get_x_cat()\n",
    "c_batch = cmodel.get_batch()\n",
    "c_num_nodes = cmodel.get_num_nodes()\n",
    "print(f'Shape of c_x_cont: {c_x_cont.shape}')\n",
    "print(f'Shape of c_x_cat: {c_x_cat.shape}')\n",
    "print(f'Shape of c_batch: {c_batch.shape}')\n",
    "print(f'Value of c_num_nodes: {c_num_nodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_cont)\n",
    "assert(np.allclose(x_cont, c_x_cont, atol=1e-5))\n",
    "assert(np.allclose(x_cat, c_x_cat, atol=1e-5))\n",
    "assert(np.allclose(batch, c_batch, atol=1e-5))\n",
    "assert(np.allclose(num_nodes, c_num_nodes, atol=1e-5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Internal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_etaphi = cmodel.get_etaphi()\n",
    "print(etaphi.shape)\n",
    "print(c_etaphi.shape)\n",
    "print(type(etaphi))\n",
    "print(type(c_etaphi))\n",
    "are_almost_equal = np.allclose(etaphi, c_etaphi, atol=1e-5)\n",
    "assert(np.allclose(etaphi, c_etaphi, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_num_edges = cmodel.get_num_edges()\n",
    "c_edge_index = cmodel.get_edge_index()\n",
    "edge_index_np = edge_index_test.squeeze(0).cpu().numpy().transpose()\n",
    "print(edge_index_np.shape)\n",
    "print(c_edge_index.shape)\n",
    "print(f'Number of C edges: {c_num_edges}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_index_np)\n",
    "print(c_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Intermediate Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_emb_cont = torch_model.graphnet.emb_cont_.cpu().numpy()\n",
    "cmodel_emb_cont = cmodel.get_emb_cont()\n",
    "# np.testing.assert_allclose(torch_model.graphnet.emb_cont_.cpu().numpy(), cmodel.get_emb_cont(), rtol=1e-5)\n",
    "print(torch_emb_cont.shape)\n",
    "print(cmodel_emb_cont.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch_emb_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cmodel_emb_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import c_radius_graph\n",
    "\n",
    "# Example points in 2D space and their corresponding batch indices\n",
    "points = [[0.0, 0.0], [1.0, 1.0], [2.0, 2.0],  # Batch 0\n",
    "          [3.0, 3.0], [4.0, 4.0],              # Batch 1\n",
    "          [5.0, 5.0], [6.0, 6.0]]              # Batch 2\n",
    "batch_indices = [0, 0, 0, 1, 1, 2, 2]  # Batch assignments\n",
    "radius = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the C++ function\n",
    "neighbors = c_radius_graph.find_neighbors_by_batch(points, batch_indices, radius)\n",
    "\n",
    "# Print neighbors\n",
    "for pair in neighbors:\n",
    "    print(f\"Point {pair[0]} is within radius of point {pair[1]}\")\n",
    "\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_tensor = torch.tensor(points)\n",
    "batch_tensor = torch.tensor(batch_indices)\n",
    "\n",
    "edge_index_pts = radius_graph(points_tensor, r=radius, batch=batch_tensor, loop=False, max_num_neighbors=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_index_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in Python\n",
    "import graphmetnetwork_bindings as gmn\n",
    "\n",
    "# Create an instance of the model\n",
    "model = gmn.GraphMetNetwork()\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights(\"path_to_weights_file.txt\")\n",
    "\n",
    "# Now, you can run the model with input data\n",
    "for i, (x_cont, x_cat, edge_index, batch) in enumerate(dataloader):\n",
    "    num_nodes = x_cont.shape[0]\n",
    "\n",
    "    # Run the PyTorch model\n",
    "    with torch.no_grad():\n",
    "        output = torch_model(x_cont.squeeze(0), x_cat.squeeze(0), edge_index.squeeze(0), batch.squeeze(0))\n",
    "\n",
    "    # Run the C++ model\n",
    "    model.GraphMetNetworkLayer(x_cont.squeeze(0).numpy(), x_cat.squeeze(0).numpy(), num_nodes, batch.squeeze(0).numpy())\n",
    "\n",
    "    # Compare intermediate values as before\n",
    "    np.testing.assert_allclose(torch_model._emb_cont.numpy(), model.get_emb_cont(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(torch_model._emb_chrg.numpy(), model.get_emb_chrg(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(torch_model._emb_pdg.numpy(), model.get_emb_pdg(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(torch_model._emb_cat.numpy(), model.get_emb_cat(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(torch_model._emb.numpy(), model.get_emb(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(torch_model._emb1.numpy(), model.get_emb1(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(torch_model._emb2.numpy(), model.get_emb2(), rtol=1e-5)\n",
    "    np.testing.assert_allclose(output.numpy(), model.get_output(), rtol=1e-5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
