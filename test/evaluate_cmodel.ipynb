{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('../../L1DeepMETv2/')\n",
    "import time\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import model.net as net\n",
    "import model.data_loader as data_loader\n",
    "from graphmetnetwork import GraphMetNetwork\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_cont = 6\n",
    "n_features_cat = 2\n",
    "scale_momentum = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, dataloader, metrics, model_dir, n_features_cont = 6, save_METarr = True, removePuppi = False):\n",
    "    \"\"\"Evaluate the model on `num_steps` batches.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # summary for current eval loop\n",
    "    loss_avg_arr = []\n",
    "    qT_arr = []\n",
    "    \n",
    "    MET_arr = {\n",
    "        'genMETx': [],\n",
    "        'genMETy': [],\n",
    "        \n",
    "        'METx': [],\n",
    "        'METy': [],\n",
    "        \n",
    "        'puppiMETx': [],\n",
    "        'puppiMETy': []\n",
    "    }\n",
    "    \n",
    "    resolutions_arr = {\n",
    "        'MET':      [[],[],[]],\n",
    "        'puppiMET': [[],[],[]],\n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "    #    'pfMET': 'black',\n",
    "        'puppiMET': 'red',\n",
    "    #    'deepMETResponse': 'blue',\n",
    "    #    'deepMETResolution': 'green',\n",
    "        'MET':  'magenta',\n",
    "    }\n",
    "\n",
    "    labels = {\n",
    "    #    'pfMET': 'PF MET',\n",
    "        'puppiMET': 'PUPPI MET',\n",
    "    #    'deepMETResponse': 'DeepMETResponse',\n",
    "    #    'deepMETResolution': 'DeepMETResolution',\n",
    "        'MET': 'DeepMETv2'\n",
    "    }\n",
    "\n",
    "    weights_pdgId_arr = {\n",
    "        'down': [],\n",
    "        'up': [],\n",
    "        'electron': [],\n",
    "        'muon': [],\n",
    "        'photon': [],\n",
    "        'kaon': [],\n",
    "        'pion': [],\n",
    "    }\n",
    "    \n",
    "    puppi_weights_pdgId_arr = {\n",
    "        'down': [],\n",
    "        'up': [],\n",
    "        'electron': [],\n",
    "        'muon': [],\n",
    "        'photon': [],\n",
    "        'kaon': [],\n",
    "        'pion': [],\n",
    "    }\n",
    "    \n",
    "    # compute metrics over the dataset\n",
    "    for data in tqdm(dataloader, desc=\"Testing Progress\", leave=False):\n",
    "        \n",
    "        if removePuppi:\n",
    "            x_cont = data.x[:,:(n_features_cont-1)]\n",
    "        else:\n",
    "            x_cont = data.x[:,:n_features_cont]\n",
    "        \n",
    "        x_cat = data.x[:,n_features_cont:].long()\n",
    "        \n",
    "        # Convert inputs to numpy arrays\n",
    "        c_x_cont = np.ascontiguousarray(x_cont.squeeze(0).numpy())\n",
    "        c_x_cat = np.ascontiguousarray(x_cat.squeeze(0).numpy())\n",
    "        c_batch = np.ascontiguousarray(data.batch.squeeze(0).numpy())\n",
    "        num_nodes = x_cont.shape[0]\n",
    "        \n",
    "        # Run forward method\n",
    "        model.GraphMetNetworkLayers(c_x_cont, c_x_cat, c_batch, num_nodes)\n",
    "        \n",
    "        # Get result\n",
    "        result = torch.from_numpy(model.get_output())\n",
    "\n",
    "        loss = loss_fn(result, data.x, data.y, data.batch)\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        resolutions, METs, weights_pdgId, puppi_weights_pdgId = metrics['resolution'](result, data.x, data.y, data.batch, scale_momentum)\n",
    "        \n",
    "        for key in resolutions_arr.keys():\n",
    "            for i in range(len(resolutions_arr[key])):\n",
    "                resolutions_arr[key][i]=np.concatenate((resolutions_arr[key][i],resolutions[key][i]))\n",
    "\n",
    "        for key in MET_arr.keys():\n",
    "            MET_arr[key]=np.concatenate((MET_arr[key],METs[key]))\n",
    "            \n",
    "        for pdg in weights_pdgId_arr.keys():\n",
    "            weights_pdgId_arr[pdg] = np.concatenate((weights_pdgId_arr[pdg],weights_pdgId[pdg]))\n",
    "            puppi_weights_pdgId_arr[pdg] = np.concatenate((puppi_weights_pdgId_arr[pdg],puppi_weights_pdgId[pdg]))\n",
    "            \n",
    "        qT_arr = np.concatenate((qT_arr, METs['genMET']))\n",
    "        \n",
    "        loss_avg_arr.append(loss.item())\n",
    "    \n",
    "    print('Done Testing, saving results...')\n",
    "    if save_METarr:\n",
    "        for key in MET_arr.keys():\n",
    "            np.savetxt(f'{model_dir}/epoch_{key}.txt', MET_arr[key].ravel(), delimiter = ',')\n",
    "        for pdg in weights_pdgId_arr.keys():\n",
    "            np.savetxt(f'{model_dir}/epoch_{pdg}_weights.txt', weights_pdgId_arr[pdg].ravel(), delimiter = ',')\n",
    "    \n",
    "    # compute mean of all metrics in summary\n",
    "    max_x=400 # max qT value\n",
    "    x_n=20 # number of bins\n",
    "\n",
    "    bin_edges=np.arange(0, max_x, max_x/x_n)\n",
    "    \n",
    "    inds=np.digitize(qT_arr, bin_edges)\n",
    "\n",
    "    qT_hist=[]\n",
    "    for i in range(1, len(bin_edges)):\n",
    "        qT_hist.append((bin_edges[i]+bin_edges[i-1])/2.)\n",
    "    \n",
    "    resolution_hists={}\n",
    "    for key in resolutions_arr:\n",
    "\n",
    "        R_arr=resolutions_arr[key][2] \n",
    "        u_perp_arr=resolutions_arr[key][0]\n",
    "        u_par_arr=resolutions_arr[key][1]\n",
    "\n",
    "        u_perp_hist=[]\n",
    "        u_perp_scaled_hist=[]\n",
    "        u_par_hist=[]\n",
    "        u_par_scaled_hist=[]\n",
    "        R_hist=[]\n",
    "\n",
    "        for i in range(1, len(bin_edges)):\n",
    "            R_i=abs(R_arr[np.where(inds==i)[0]])\n",
    "            R_hist.append(np.mean(R_i))\n",
    "            \n",
    "            u_perp_i=u_perp_arr[np.where(inds==i)[0]]\n",
    "            u_perp_scaled_i=u_perp_i/np.mean(R_i)\n",
    "            u_perp_hist.append((np.quantile(u_perp_i,0.84)-np.quantile(u_perp_i,0.16))/2.)\n",
    "            u_perp_scaled_hist.append((np.quantile(u_perp_scaled_i,0.84)-np.quantile(u_perp_scaled_i,0.16))/2.)\n",
    "            \n",
    "            u_par_i=u_par_arr[np.where(inds==i)[0]]\n",
    "            u_par_scaled_i=u_par_i/np.mean(R_i)\n",
    "            u_par_hist.append((np.quantile(u_par_i,0.84)-np.quantile(u_par_i,0.16))/2.)\n",
    "            u_par_scaled_hist.append((np.quantile(u_par_scaled_i,0.84)-np.quantile(u_par_scaled_i,0.16))/2.)\n",
    "\n",
    "        u_perp_resolution=np.histogram(qT_hist, bins=x_n, range=(0,max_x), weights=u_perp_hist)\n",
    "        u_perp_scaled_resolution=np.histogram(qT_hist, bins=x_n, range=(0,max_x), weights=u_perp_scaled_hist)\n",
    "        u_par_resolution=np.histogram(qT_hist, bins=x_n, range=(0,max_x), weights=u_par_hist)\n",
    "        u_par_scaled_resolution=np.histogram(qT_hist, bins=x_n, range=(0,max_x), weights=u_par_scaled_hist)\n",
    "        R=np.histogram(qT_hist, bins=x_n, range=(0,max_x), weights=R_hist)\n",
    "        resolution_hists[key] = {\n",
    "            'u_perp_resolution': u_perp_resolution,\n",
    "            'u_perp_scaled_resolution': u_perp_scaled_resolution,\n",
    "            'u_par_resolution': u_par_resolution,\n",
    "            'u_par_scaled_resolution':u_par_scaled_resolution,\n",
    "            'R': R\n",
    "        }\n",
    "    \n",
    "    metrics_mean = {\n",
    "        'loss': np.mean(loss_avg_arr),\n",
    "        #'resolution': (np.quantile(resolutions_arr,0.84)-np.quantile(resolutions_arr,0.16))/2.\n",
    "    }\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
    "                                for k, v in metrics_mean.items())\n",
    "    print(\"- Eval metrics : \" + metrics_string)\n",
    "    \n",
    "    return metrics_mean, resolution_hists, MET_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../L1DeepMETv2/data_ttbar'\n",
    "output_dir = \"weights_files/\"\n",
    "dataloaders = data_loader.fetch_dataloader(data_dir = data_dir, batch_size=1, validation_split=.2)\n",
    "test_dl = dataloaders['test']\n",
    "loss_fn = net.loss_fn\n",
    "metrics = net.metrics\n",
    "model_dir = osp.join(os.environ['PWD'],'ckpts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the C++ GraphMetNetwork model\n",
    "model = GraphMetNetwork()\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = evaluate(model, loss_fn, test_dl, metrics, model_dir)   \n",
    "resolutions = test_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics in a json file in the model directory\n",
    "utils.save_dict_to_json(test_metrics, osp.join(model_dir, 'metrics_val_best.json'))\n",
    "utils.save(resolutions, osp.join(model_dir, 'best.resolutions'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
