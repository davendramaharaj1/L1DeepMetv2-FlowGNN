{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/dvsm3/.conda/envs/deepmet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import os.path as osp\n",
    "sys.path\n",
    "sys.path.append('../../L1DeepMETv2/')\n",
    "from graphmetnetwork import GraphMetNetwork\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_cluster import radius_graph, knn_graph\n",
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import model.net as net\n",
    "import model.data_loader as data_loader\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "0it [00:00, ?it/s]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 199708\n",
      "length of train/val data:  798834 199708\n",
      "Test dataloader: 199708\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/dvsm3/.conda/envs/deepmet/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../L1DeepMETv2/data_ttbar'\n",
    "dataloaders = data_loader.fetch_dataloader(data_dir = data_dir, batch_size=1, validation_split=.2)\n",
    "test_dl = dataloaders['test']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Test dataloader: {}'.format(len(test_dl)))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../../L1DeepMETv2/ckpts_April30_scale_sigmoid'\n",
    "restore_ckpt = osp.join(prefix, 'last.pth.tar')\n",
    "norm = torch.tensor([1., 1., 1., 1., 1., 1.]).to(device=device)\n",
    "torch_model = net.Net(continuous_dim=6, categorical_dim=2 , norm=norm).to(device)\n",
    "print(torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_restored_new = utils.load_checkpoint(restore_ckpt, torch_model)\n",
    "weights_dict = param_restored_new['state_dict']\n",
    "epoch = param_restored_new['epoch']\n",
    "torch_model.eval()  # Set the torch model to eval mode\n",
    "print(weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store weights in binaries for C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"weights_files/\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(output_dir):\n",
    "    # Iterate over all the files in the directory\n",
    "    for filename in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            # Check if it's a file and delete it\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            # If it's a directory, delete the directory and its contents\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "else:\n",
    "    print(f\"Directory {output_dir} does not exist.\")\n",
    "\n",
    "\n",
    "# Function to save the weights as binary files\n",
    "def save_weights_as_binary(weights_dict, output_dir):\n",
    "    for key, tensor in weights_dict.items():\n",
    "        # Convert the tensor to a NumPy array\n",
    "        np_array = tensor.cpu().numpy()\n",
    "\n",
    "        # Create a binary file name based on the tensor name\n",
    "        file_name = output_dir + key.replace('.', '_') + '.bin'\n",
    "\n",
    "        # Save the NumPy array as a binary file\n",
    "        np_array.tofile(file_name)\n",
    "        \n",
    "# Save all weights in the OrderedDict to binary files\n",
    "save_weights_as_binary(weights_dict, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load C++ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the C++ GraphMetNetwork model\n",
    "cmodel = GraphMetNetwork()\n",
    "\n",
    "# Load the weights\n",
    "cmodel.load_weights(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify weights are the same between torch model and C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_weights = 0\n",
    "for key, tensor in weights_dict.items():\n",
    "    # Convert the tensor to a NumPy array\n",
    "    np_array = tensor.cpu().numpy()\n",
    "\n",
    "    # Return cmodel function pointer to get the weight array\n",
    "    cmodel_weight_func_name = 'get_' + key.replace('.', '_')\n",
    "    cmodel_weight_func = getattr(cmodel, cmodel_weight_func_name)\n",
    "    cmodel_weight_array = cmodel_weight_func()\n",
    "    \n",
    "    # Compare Torch model weight with Cmodel weight\n",
    "    assert(np.allclose(np_array, cmodel_weight_array, atol=1e-5)), f'cmodel.{cmodel_weight_func_name} returned the wrong weights'\n",
    "    num_weights += 1\n",
    "\n",
    "print(f'Number of weights checked: {num_weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference and compare outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# List to track errors\n",
    "failed_cases = []\n",
    "\n",
    "# Run the model with input data\n",
    "counter = 0\n",
    "for data in tqdm(test_dl, desc=\"Testing Progress\", leave=False):\n",
    "    data = data.to(device)\n",
    "    \n",
    "    x_cont = data.x[:,:6]  # include puppi\n",
    "    x_cat = data.x[:,6:].long()\n",
    "    num_nodes = x_cont.shape[0]\n",
    "    \n",
    "    etaphi = torch.cat([data.x[:,3][:,None], data.x[:,4][:,None]], dim=1)\n",
    "    edge_index = radius_graph(etaphi, r=0.4, batch=data.batch, loop=False, max_num_neighbors=255)  # turn off self-loop\n",
    "    \n",
    "    x_cont_c = np.ascontiguousarray(x_cont.cpu().numpy())\n",
    "    x_cat_c = np.ascontiguousarray(x_cat.cpu().numpy())\n",
    "    batch_c = np.ascontiguousarray(data.batch.cpu().numpy())\n",
    "\n",
    "    # Run the PyTorch model\n",
    "    torch_output = torch_model(x_cont, x_cat, edge_index, data.batch)\n",
    "    torch_output_np = torch_output.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # Run the C++ model\n",
    "    cmodel.GraphMetNetworkLayers(x_cont_c, x_cat_c, batch_c, num_nodes)\n",
    "    c_output = np.array(cmodel.get_output()).astype(np.float32)\n",
    "\n",
    "    try:\n",
    "        # Compare the outputs\n",
    "        np.testing.assert_allclose(c_output, torch_output_np, rtol=1e-3, err_msg=f'test_dl counter = {counter} failed')\n",
    "    except AssertionError as e:\n",
    "        # Log the failed case\n",
    "        max_abs_diff = np.max(np.abs(c_output - torch_output_np))\n",
    "        max_rel_diff = np.max(np.abs(c_output - torch_output_np) / np.abs(torch_output_np))\n",
    "        \n",
    "        failed_cases.append({\n",
    "            'counter': counter,\n",
    "            'c_output': c_output.tolist(),\n",
    "            'torch_output': torch_output_np.tolist(),\n",
    "            'max_abs_diff': float(max_abs_diff),\n",
    "            'max_rel_diff': float(max_rel_diff),\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "# Save failed cases to a JSON file\n",
    "with open(\"failed_cases_relu.json\", \"w\") as f:\n",
    "    json.dump(failed_cases, f, indent=4)\n",
    "\n",
    "print(f\"Total failed cases: {len(failed_cases)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
